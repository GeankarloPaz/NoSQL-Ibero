
> EquipoReplicaSet = new ReplSetTest ({name: "EquipoReplicaSet", nodes: 3})
Starting new replica set EquipoReplicaSet
{
        "kDefaultTimeoutMS" : 600000,
        "getReadConcernMajorityOpTimeOrThrow" : function(conn) {
        const majorityOpTime = _getReadConcernMajorityOpTime(conn);
        if (friendlyEqual(majorityOpTime, {ts: Timestamp(0, 0), t: NumberLong(0)})) {
            throw new Error("readConcern majority optime not available");
        }
        return majorityOpTime;
    },
        "nodeList" : function() {
        var list = [];
        for (var i = 0; i < this.ports.length; i++) {
            list.push(this.host + ":" + this.ports[i]);
        }

        return list;
    },
        "getNodeId" : function(node) {
        if (node.toFixed) {
            return parseInt(node);
        }

        for (var i = 0; i < this.nodes.length; i++) {
            if (this.nodes[i] == node) {
                return i;
            }
        }

        if (node instanceof ObjectId) {
            for (i = 0; i < this.nodes.length; i++) {
                if (this.nodes[i].runId == node) {
                    return i;
                }
            }
        }

        if (node.nodeId != null) {
            return parseInt(node.nodeId);
        }

        return undefined;
    },
        "getPort" : function(n) {
        var n = this.getNodeId(n);
        return this.ports[n];
    },
        "getDbPath" : function(node) {
        // Get a replica set node (check for use of bridge).
        const n = this.getNodeId(node);
        const replNode = _useBridge ? _unbridgedNodes[n] : this.nodes[n];
        return replNode.dbpath;
    },
        "_addPath" : function(p) {
        if (!_alldbpaths)
            _alldbpaths = [p];
        else
            _alldbpaths.push(p);

        return p;
    },
        "getReplSetConfig" : function() {
        var cfg = {};
        cfg._id = this.name;
        cfg.protocolVersion = 1;

        cfg.members = [];

        for (var i = 0; i < this.ports.length; i++) {
            var member = {};
            member._id = i;

            member.host = this.host;
            if (!member.host.includes('/')) {
                member.host += ":" + this.ports[i];
            }

            var nodeOpts = this.nodeOptions["n" + i];
            if (nodeOpts) {
                if (nodeOpts.arbiter) {
                    member.arbiterOnly = true;
                }

                if (nodeOpts.rsConfig) {
                    Object.extend(member, nodeOpts.rsConfig);
                }
            }

            cfg.members.push(member);
        }

        if (_configSettings) {
            cfg.settings = _configSettings;
        }

        return cfg;
    },
        "getURL" : function() {
        var hosts = [];

        for (var i = 0; i < this.ports.length; i++) {
            hosts.push(this.host + ":" + this.ports[i]);
        }

        return this.name + "/" + hosts.join(",");
    },
        "startSet" : function(options, restart) {
        print("ReplSetTest starting set");

        if (options && options.keyFile) {
            self.keyFile = options.keyFile;
        }

        if (options) {
            self.startOptions = options;
        }

        var nodes = [];
        for (var n = 0; n < this.ports.length; n++) {
            nodes.push(this.start(n, options, restart));
        }

        this.nodes = nodes;
        return this.nodes;
    },
        "awaitSecondaryNodes" : function(timeout, slaves) {
        timeout = timeout || self.kDefaultTimeoutMS;

        assert.soonNoExcept(function() {
            // Reload who the current slaves are
            self.getPrimary(timeout);

            var slavesToCheck = slaves || self._slaves;
            var len = slavesToCheck.length;
            var ready = true;

            for (var i = 0; i < len; i++) {
                var isMaster = slavesToCheck[i].adminCommand({ismaster: 1});
                var arbiter = (isMaster.arbiterOnly === undefined ? false : isMaster.arbiterOnly);
                ready = ready && (isMaster.secondary || arbiter);
            }

            return ready;
        }, "Awaiting secondaries", timeout);
    },
        "awaitSecondaryNodesForRollbackTest" : function(
        timeout, slaves, connToCheckForUnrecoverableRollback) {
        try {
            this.awaitSecondaryNodes(timeout, slaves);
        } catch (originalEx) {
            // There is a special case where we expect the (rare) possibility of unrecoverable
            // rollbacks with EMRC:false in rollback suites with unclean shutdowns.
            jsTestLog("Exception in 'awaitSecondaryNodes', checking for unrecoverable rollback");
            if (connToCheckForUnrecoverableRollback) {
                const conn = connToCheckForUnrecoverableRollback;

                const statusRes = assert.commandWorked(conn.adminCommand({replSetGetStatus: 1}));
                const isRecovering = (statusRes.myState === ReplSetTest.State.RECOVERING);
                const hasNoSyncSource = (statusRes.syncSourceId === -1);

                const cmdLineOptsRes = assert.commandWorked(conn.adminCommand("getCmdLineOpts"));
                const hasEMRCFalse =
                    (cmdLineOptsRes.parsed.replication.enableMajorityReadConcern === false);

                if (isRecovering && hasNoSyncSource && hasEMRCFalse) {
                    try {
                        const n = this.getNodeId(conn);
                        const connToCheck = _useBridge ? _unbridgedNodes[n] : this.nodes[n];
                        // Confirm that the node is unable to recover after rolling back.
                        checkLog.contains(
                            connToCheck,
                            "remote oplog does not contain entry with optime matching our required optime ",
                            60 * 1000);
                    } catch (checkLogEx) {
                        throw originalEx;
                    }
                    // Add this info to the original exception.
                    originalEx.unrecoverableRollbackDetected = true;
                }
            }
            // Re-throw the original exception in all cases.
            throw originalEx;
        }
    },
        "awaitSyncSource" : function(node, upstreamNode, timeout) {
        print("Waiting for node " + node.name + " to start syncing from " + upstreamNode.name);
        var status = null;
        assert.soonNoExcept(
            function() {
                status = node.getDB("admin").runCommand({replSetGetStatus: 1});
                for (var j = 0; j < status.members.length; j++) {
                    if (status.members[j].self) {
                        return status.members[j].syncingTo === upstreamNode.host;
                    }
                }
                return false;
            },
            "Awaiting node " + node + " syncing from " + upstreamNode + ": " + tojson(status),
            timeout);
    },
        "awaitNodesAgreeOnAppliedOpTime" : function(timeout, nodes) {
        timeout = timeout || self.kDefaultTimeoutMS;
        nodes = nodes || self.nodes;

        assert.soon(function() {
            let appliedOpTimeConsensus = undefined;
            for (let i = 0; i < nodes.length; i++) {
                let replSetGetStatus;
                try {
                    replSetGetStatus = nodes[i].adminCommand({replSetGetStatus: 1});
                } catch (e) {
                    print("AwaitNodesAgreeOnAppliedOpTime: Retrying because node " + nodes[i].name +
                          " failed to execute replSetGetStatus: " + tojson(e));
                    return false;
                }
                assert.commandWorked(replSetGetStatus);

                if (appliedOpTimeConsensus === undefined) {
                    if (replSetGetStatus.optimes) {
                        appliedOpTimeConsensus = replSetGetStatus.optimes.appliedOpTime;
                    } else {
                        // Older versions of mongod do not include an 'optimes' field in the
                        // replSetGetStatus response. We instead pull an optime from the first
                        // replica set member that includes one in its status. All we need here is
                        // any initial value that we can compare to all the other optimes.
                        let optimeMembers = replSetGetStatus.members.filter(m => m.optime);
                        assert(optimeMembers.length > 0,
                               "AwaitNodesAgreeOnAppliedOpTime: replSetGetStatus did not " +
                                   "include optimes for any members: " + tojson(replSetGetStatus));
                        appliedOpTimeConsensus = optimeMembers[0].optime;
                    }

                    assert(appliedOpTimeConsensus,
                           "AwaitNodesAgreeOnAppliedOpTime: missing appliedOpTime in " +
                               "replSetGetStatus: " + tojson(replSetGetStatus));
                }

                if (replSetGetStatus.optimes &&
                    !friendlyEqual(replSetGetStatus.optimes.appliedOpTime,
                                   appliedOpTimeConsensus)) {
                    print("AwaitNodesAgreeOnAppliedOpTime: Retrying because node " + nodes[i].name +
                          " has appliedOpTime " + tojson(replSetGetStatus.optimes.appliedOpTime) +
                          " that does not match the previously observed appliedOpTime " +
                          tojson(appliedOpTimeConsensus));
                    return false;
                }

                for (let j = 0; j < replSetGetStatus.members.length; j++) {
                    if (replSetGetStatus.members[j].state == ReplSetTest.State.ARBITER) {
                        // ARBITER nodes do not apply oplog entries and do not have an 'optime'
                        // field.
                        continue;
                    }

                    if (!friendlyEqual(replSetGetStatus.members[j].optime,
                                       appliedOpTimeConsensus)) {
                        print("AwaitNodesAgreeOnAppliedOpTime: Retrying because node " +
                              nodes[i].name + " sees optime " +
                              tojson(replSetGetStatus.members[j].optime) + " on node " +
                              replSetGetStatus.members[j].name + " but expects to see optime " +
                              tojson(appliedOpTimeConsensus));
                        return false;
                    }
                }
            }

            print(
                "AwaitNodesAgreeOnAppliedOpTime: All nodes agree that all ops are applied up to " +
                tojson(appliedOpTimeConsensus));
            return true;
        }, "Awaiting nodes to agree that all ops are applied across replica set", timeout);
    },
        "_findHighestPriorityNodes" : function(config) {
        let highestPriority = 0;
        let highPriorityNodes = [];
        for (let i = 0; i < config.members.length; i++) {
            const member = config.members[i];
            if (member.priority > highestPriority) {
                highestPriority = member.priority;
                highPriorityNodes = [this.nodes[i]];
            } else if (member.priority === highestPriority) {
                highPriorityNodes.push(this.nodes[i]);
            }
        }
        return highPriorityNodes;
    },
        "awaitHighestPriorityNodeIsPrimary" : function(timeout) {
        timeout = timeout || self.kDefaultTimeoutMS;

        // First figure out the set of highest priority nodes.
        const config = asCluster(this.nodes, () => self.getReplSetConfigFromNode());
        const highPriorityNodes = this._findHighestPriorityNodes(config);

        // Now wait for the primary to be one of the highest priority nodes.
        assert.soon(
            function() {
                return highPriorityNodes.includes(self.getPrimary());
            },
            function() {
                return "Expected primary to be one of: " + tojson(highPriorityNodes) +
                    ", but found primary to be: " + tojson(self.getPrimary());
            },
            timeout);

        // Finally wait for all nodes to agree on the primary.
        this.awaitNodesAgreeOnPrimary(timeout);
        const primary = this.getPrimary();
        assert(highPriorityNodes.includes(primary),
               "Primary switched away from highest priority node.  Found primary: " +
                   tojson(primary) + ", but expected one of: " + tojson(highPriorityNodes));
    },
        "awaitNodesAgreeOnPrimary" : function(timeout, nodes, expectedPrimaryNodeId) {
        timeout = timeout || self.kDefaultTimeoutMS;
        nodes = nodes || self.nodes;
        expectedPrimaryNodeId = expectedPrimaryNodeId || -1;
        if (expectedPrimaryNodeId === -1) {
            print("AwaitNodesAgreeOnPrimary: Waiting for nodes to agree on any primary.");
        } else {
            print("AwaitNodesAgreeOnPrimary: Waiting for nodes to agree on " +
                  nodes[expectedPrimaryNodeId].name + " as primary.");
        }

        assert.soonNoExcept(function() {
            var primary = expectedPrimaryNodeId;

            for (var i = 0; i < nodes.length; i++) {
                var replSetGetStatus =
                    assert.commandWorked(nodes[i].getDB("admin").runCommand({replSetGetStatus: 1}));
                var nodesPrimary = -1;
                for (var j = 0; j < replSetGetStatus.members.length; j++) {
                    if (replSetGetStatus.members[j].state === ReplSetTest.State.PRIMARY) {
                        // Node sees two primaries.
                        if (nodesPrimary !== -1) {
                            print("AwaitNodesAgreeOnPrimary: Retrying because " + nodes[i].name +
                                  " thinks both " + self.nodes[nodesPrimary].name + " and " +
                                  self.nodes[j].name + " are primary.");

                            return false;
                        }
                        nodesPrimary = j;
                    }
                }
                // Node doesn't see a primary.
                if (nodesPrimary < 0) {
                    print("AwaitNodesAgreeOnPrimary: Retrying because " + nodes[i].name +
                          " does not see a primary.");
                    return false;
                }

                if (primary < 0) {
                    // If we haven't seen a primary yet, set it to this.
                    primary = nodesPrimary;
                } else if (primary !== nodesPrimary) {
                    print("AwaitNodesAgreeOnPrimary: Retrying because " + nodes[i].name +
                          " thinks the primary is " + self.nodes[nodesPrimary].name +
                          " instead of " + self.nodes[primary].name);
                    return false;
                }
            }

            print("AwaitNodesAgreeOnPrimary: Nodes agreed on primary " + self.nodes[primary].name);
            return true;
        }, "Awaiting nodes to agree on primary timed out", timeout);
    },
        "getPrimary" : function(timeout) {
        timeout = timeout || self.kDefaultTimeoutMS;
        var primary = null;

        assert.soonNoExcept(function() {
            primary = _callIsMaster();
            return primary;
        }, "Finding primary", timeout);

        return primary;
    },
        "awaitNoPrimary" : function(msg, timeout) {
        msg = msg || "Timed out waiting for there to be no primary in replset: " + this.name;
        timeout = timeout || self.kDefaultTimeoutMS;

        assert.soonNoExcept(function() {
            return _callIsMaster() == false;
        }, msg, timeout);
    },
        "getSecondaries" : function(timeout) {
        var master = this.getPrimary(timeout);
        var secs = [];
        for (var i = 0; i < this.nodes.length; i++) {
            if (this.nodes[i] != master) {
                secs.push(this.nodes[i]);
            }
        }

        return secs;
    },
        "getSecondary" : function(timeout) {
        return this.getSecondaries(timeout)[0];
    },
        "getArbiters" : function() {
        let arbiters = [];
        for (let i = 0; i < this.nodes.length; i++) {
            const node = this.nodes[i];

            let isArbiter = false;

            assert.retryNoExcept(() => {
                isArbiter = isNodeArbiter(node);
                return true;
            }, `Could not call 'isMaster' on ${node}.`, 3, 1000);

            if (isArbiter) {
                arbiters.push(node);
            }
        }
        return arbiters;
    },
        "getArbiter" : function() {
        return this.getArbiters()[0];
    },
        "status" : function(timeout) {
        var master = _callIsMaster();
        if (!master) {
            master = this._liveNodes[0];
        }

        return master.getDB("admin").runCommand({replSetGetStatus: 1});
    },
        "add" : function(config) {
        var nextPort = _allocatePortForNode();
        print("ReplSetTest Next port: " + nextPort);

        this.ports.push(nextPort);
        printjson(this.ports);

        if (_useBridge) {
            _unbridgedPorts.push(_allocatePortForBridge());
        }

        var nextId = this.nodes.length;
        printjson(this.nodes);

        print("ReplSetTest nextId: " + nextId);
        return this.start(nextId, config);
    },
        "remove" : function(nodeId) {
        nodeId = this.getNodeId(nodeId);
        this.nodes.splice(nodeId, 1);
        this.ports.splice(nodeId, 1);

        if (_useBridge) {
            _unbridgedPorts.splice(nodeId, 1);
            _unbridgedNodes.splice(nodeId, 1);
        }
    },
        "_updateConfigIfNotDurable" : function(config) {
        // Get a replica set node (check for use of bridge).
        var replNode = _useBridge ? _unbridgedNodes[0] : this.nodes[0];

        // Don't update replset config for sharding config servers since config servers always
        // require durable storage.
        if (replNode.hasOwnProperty("fullOptions") &&
            replNode.fullOptions.hasOwnProperty("configsvr")) {
            return config;
        }

        // Don't override existing value.
        var wcMajorityJournalField = "writeConcernMajorityJournalDefault";
        if (config.hasOwnProperty(wcMajorityJournalField)) {
            return config;
        }

        // Check journaling by sending commands through the bridge if it's used.
        if (_isRunningWithoutJournaling(this.nodes[0])) {
            config[wcMajorityJournalField] = false;
        }

        return config;
    },
        "_setDefaultConfigOptions" : function(config) {
        // Update config for non journaling test variants
        this._updateConfigIfNotDurable(config);
        // Add protocolVersion if missing
        if (!config.hasOwnProperty('protocolVersion')) {
            config['protocolVersion'] = 1;
        }
    },
        "initiateWithAnyNodeAsPrimary" : function(cfg, initCmd, {
        doNotWaitForStableRecoveryTimestamp: doNotWaitForStableRecoveryTimestamp = false
    } = {}) {
        var master = this.nodes[0].getDB("admin");
        var config = cfg || this.getReplSetConfig();
        var cmd = {};
        var cmdKey = initCmd || 'replSetInitiate';

        // Throw an exception if nodes[0] is unelectable in the given config.
        if (!_isElectable(config.members[0])) {
            throw Error("The node at index 0 must be electable");
        }

        // Start up a single node replica set then reconfigure to the correct size (if the config
        // contains more than 1 node), so the primary is elected more quickly.
        var originalMembers, originalSettings;
        if (config.members && config.members.length > 1) {
            originalMembers = config.members.slice();
            config.members = config.members.slice(0, 1);
            originalSettings = config.settings;
            delete config.settings;  // Clear settings to avoid tags referencing sliced nodes.
        }
        this._setDefaultConfigOptions(config);

        cmd[cmdKey] = config;

        // replSetInitiate and replSetReconfig commands can fail with a NodeNotFound error if a
        // heartbeat times out during the quorum check. They may also fail with
        // NewReplicaSetConfigurationIncompatible on similar timeout during the config validation
        // stage while deducing isSelf(). This can fail with an InterruptedDueToReplStateChange
        // error when interrupted. We try several times, to reduce the chance of failing this way.
        replSetCommandWithRetry(master, cmd);
        this.getPrimary();  // Blocks until there is a primary.

        // Reconfigure the set to contain the correct number of nodes (if necessary).
        if (originalMembers) {
            config.members = originalMembers;
            if (originalSettings) {
                config.settings = originalSettings;
            }
            config.version = 2;

            // Nodes started with the --configsvr flag must have configsvr = true in their config.
            if (this.nodes[0].hasOwnProperty("fullOptions") &&
                this.nodes[0].fullOptions.hasOwnProperty("configsvr")) {
                config.configsvr = true;
            }

            cmd = {replSetReconfig: config};
            print("Reconfiguring replica set to add in other nodes");
            replSetCommandWithRetry(master, cmd);
        }

        // Setup authentication if running test with authentication
        if ((jsTestOptions().keyFile) && cmdKey == 'replSetInitiate') {
            master = this.getPrimary();
            jsTest.authenticateNodes(this.nodes);
        }
        this.awaitSecondaryNodes();
        try {
            this.awaitHighestPriorityNodeIsPrimary();
        } catch (e) {
            // Due to SERVER-14017, the call to awaitHighestPriorityNodeIsPrimary() may fail
            // in certain configurations due to being unauthorized.  In that case we proceed
            // even though we aren't guaranteed that the highest priority node is the one that
            // became primary.
            // TODO(SERVER-14017): Unconditionally expect awaitHighestPriorityNodeIsPrimary to pass.
            assert.eq(ErrorCodes.Unauthorized, e.code, tojson(e));
            print("Running awaitHighestPriorityNodeIsPrimary() during ReplSetTest initialization " +
                  "failed with Unauthorized error, proceeding even though we aren't guaranteed " +
                  "that the highest priority node is primary");
        }

        let shouldWaitForKeys = true;
        if (self.waitForKeys != undefined) {
            shouldWaitForKeys = self.waitForKeys;
            print("Set shouldWaitForKeys from RS options: " + shouldWaitForKeys);
        } else {
            Object.keys(self.nodeOptions).forEach(function(key, index) {
                let val = self.nodeOptions[key];
                if (typeof (val) === "object" &&
                    (val.hasOwnProperty("shardsvr") ||
                     val.hasOwnProperty("binVersion") &&
                         // Should not wait for keys if version is less than 3.6
                         MongoRunner.compareBinVersions(val.binVersion, "3.6") == -1)) {
                    shouldWaitForKeys = false;
                    print("Set shouldWaitForKeys from node options: " + shouldWaitForKeys);
                }
            });
            if (self.startOptions != undefined) {
                let val = self.startOptions;
                if (typeof (val) === "object" &&
                    (val.hasOwnProperty("shardsvr") ||
                     val.hasOwnProperty("binVersion") &&
                         // Should not wait for keys if version is less than 3.6
                         MongoRunner.compareBinVersions(val.binVersion, "3.6") == -1)) {
                    shouldWaitForKeys = false;
                    print("Set shouldWaitForKeys from start options: " + shouldWaitForKeys);
                }
            }
        }
        /**
         * Blocks until the primary node generates cluster time sign keys.
         */
        if (shouldWaitForKeys) {
            var timeout = self.kDefaultTimeoutMS;
            asCluster(this.nodes, function(timeout) {
                print("Waiting for keys to sign $clusterTime to be generated");
                assert.soonNoExcept(function(timeout) {
                    var keyCnt = self.getPrimary(timeout)
                                     .getCollection('admin.system.keys')
                                     .find({purpose: 'HMAC'})
                                     .itcount();
                    return keyCnt >= 2;
                }, "Awaiting keys", timeout);
            });
        }

        // Set 'featureCompatibilityVersion' for the entire replica set, if specified.
        if (jsTest.options().replSetFeatureCompatibilityVersion) {
            // Authenticate before running the command.
            asCluster(self.nodes, function setFCV() {
                let fcv = jsTest.options().replSetFeatureCompatibilityVersion;
                print("Setting feature compatibility version for replica set to '" + fcv + "'");
                assert.commandWorked(
                    self.getPrimary().adminCommand({setFeatureCompatibilityVersion: fcv}));

                // Wait for the new 'featureCompatibilityVersion' to propagate to all nodes in the
                // replica set. The 'setFeatureCompatibilityVersion' command only waits for
                // replication to a majority of nodes by default.
                self.awaitReplication();
            });
        }

        if (!doNotWaitForStableRecoveryTimestamp) {
            self.awaitLastStableRecoveryTimestamp();
        }
    },
        "initiateWithNodeZeroAsPrimary" : function(cfg, initCmd) {
        this.initiateWithAnyNodeAsPrimary(cfg, initCmd);

        // stepUp() calls awaitReplication() which requires all nodes to be authorized to run
        // replSetGetStatus.
        asCluster(this.nodes, function() {
            self.stepUp(self.nodes[0]);
        });
    },
        "initiate" : function(cfg, initCmd) {
        this.initiateWithNodeZeroAsPrimary(cfg, initCmd);
    },
        "initiateWithHighElectionTimeout" : function(config) {
        config = config || this.getReplSetConfig();
        config.settings = config.settings || {};
        config.settings["electionTimeoutMillis"] = ReplSetTest.kForeverMillis;
        this.initiate(config);
    },
        "stepUp" : function(node, {
        awaitReplicationBeforeStepUp: awaitReplicationBeforeStepUp = true,
        awaitWritablePrimary: awaitWritablePrimary = true
    } = {}) {
        jsTest.log("ReplSetTest stepUp: Stepping up " + node.host);

        if (awaitReplicationBeforeStepUp) {
            this.awaitReplication();
        }

        assert.soonNoExcept(() => {
            const res = node.adminCommand({replSetStepUp: 1});
            // This error is possible if we are running mongoDB binary < 3.4 as
            // part of multi-version upgrade test. So, for those older branches,
            // simply wait for the requested node to get elected as primary due
            // to election timeout.
            if (!res.ok && res.code === ErrorCodes.CommandNotFound) {
                jsTest.log(
                    'replSetStepUp command not supported on node ' + node.host +
                    " ; so wait for the requested node to get elected due to election timeout.");
                if (this.getPrimary() === node) {
                    return true;
                }
            }
            assert.commandWorked(res);

            // Since assert.soon() timeout is 10 minutes (default), setting
            // awaitNodesAgreeOnPrimary() timeout as 1 minute to allow retry of replSetStepUp
            // command on failure of the replica set to agree on the primary.
            const timeout = 60 * 1000;
            this.awaitNodesAgreeOnPrimary(timeout, this.nodes, this.getNodeId(node));

            // getPrimary() guarantees that there will be only one writable primary for a replica
            // set.
            if (!awaitWritablePrimary || this.getPrimary() === node) {
                return true;
            }

            jsTest.log(node.host + ' is not primary after stepUp command');
            return false;
        }, "Timed out while waiting for stepUp to succeed on node in port: " + node.port);

        jsTest.log("ReplSetTest stepUp: Finished stepping up " + node.host);
        return node;
    },
        "getReplSetConfigFromNode" : function(nodeId) {
        if (nodeId == undefined) {
            // Use 90 seconds timeout for finding a primary
            return _replSetGetConfig(self.getPrimary(90 * 1000));
        }

        if (!isNumber(nodeId)) {
            throw Error(nodeId + ' is not a number');
        }

        return _replSetGetConfig(self.nodes[nodeId]);
    },
        "reInitiate" : function() {
        var config = this.getReplSetConfigFromNode();
        var newConfig = this.getReplSetConfig();
        // Only reset members.
        config.members = newConfig.members;
        config.version += 1;

        this._setDefaultConfigOptions(config);

        assert.adminCommandWorkedAllowingNetworkError(this.getPrimary(), {replSetReconfig: config});
    },
        "awaitNodesAgreeOnConfigVersion" : function(timeout) {
        timeout = timeout || this.kDefaultTimeoutMS;

        assert.soonNoExcept(function() {
            var primaryVersion = self.getPrimary().adminCommand({ismaster: 1}).setVersion;

            for (var i = 0; i < self.nodes.length; i++) {
                var version = self.nodes[i].adminCommand({ismaster: 1}).setVersion;
                assert.eq(version,
                          primaryVersion,
                          "waiting for secondary node " + self.nodes[i].host +
                              " with config version of " + version +
                              " to match the version of the primary " + primaryVersion);
            }

            return true;
        }, "Awaiting nodes to agree on config version", timeout);
    },
        "awaitLastOpCommitted" : function(timeout, members) {
        var rst = this;
        var master = rst.getPrimary();
        var masterOpTime = _getLastOpTime(master);

        let membersToCheck;
        if (members !== undefined) {
            print("Waiting for op with OpTime " + tojson(masterOpTime) + " to be committed on " +
                  members.map(s => s.host));

            membersToCheck = members;
        } else {
            print("Waiting for op with OpTime " + tojson(masterOpTime) +
                  " to be committed on all secondaries");

            membersToCheck = rst.nodes;
        }

        assert.soonNoExcept(
            function() {
                for (var i = 0; i < membersToCheck.length; i++) {
                    var node = membersToCheck[i];

                    // Continue if we're connected to an arbiter
                    var res = assert.commandWorked(node.adminCommand({replSetGetStatus: 1}));
                    if (res.myState == ReplSetTest.State.ARBITER) {
                        continue;
                    }
                    var rcmOpTime = _getReadConcernMajorityOpTime(node);
                    if (friendlyEqual(rcmOpTime, {ts: Timestamp(0, 0), t: NumberLong(0)})) {
                        return false;
                    }
                    if (rs.compareOpTimes(rcmOpTime, masterOpTime) < 0) {
                        return false;
                    }
                }

                return true;
            },
            "Op with OpTime " + tojson(masterOpTime) + " failed to be committed on all secondaries",
            timeout);

        return masterOpTime;
    },
        "awaitLastStableRecoveryTimestamp" : function() {
        let rst = this;
        let master = rst.getPrimary();
        let id = tojson(rst.nodeList());

        // All nodes must be in primary/secondary state prior to this point. Perform a majority
        // write to ensure there is a committed operation on the set. The commit point will
        // propagate to all members and trigger a stable checkpoint on all persisted storage engines
        // nodes.
        function advanceCommitPoint(master) {
            // Shadow 'db' so that we can call 'advanceCommitPoint' directly on the primary node.
            let db = master.getDB('admin');
            const appendOplogNoteFn = function() {
                assert.commandWorked(db.adminCommand({
                    "appendOplogNote": 1,
                    "data": {"awaitLastStableRecoveryTimestamp": 1},
                    "writeConcern": {"w": "majority", "wtimeout": ReplSetTest.kDefaultTimeoutMS}
                }));

                // Perform a second write, in case some node had lost its sync source.
                // TODO SERVER-40211: Remove the second write.
                assert.commandWorked(db.adminCommand(
                    {"appendOplogNote": 1, "data": {"awaitLastStableRecoveryTimestamp": 2}}));
            };

            // TODO(SERVER-14017): Remove this extra sub-shell in favor of a cleaner authentication
            // solution.
            const masterId = "n" + rst.getNodeId(master);
            const masterOptions = rst.nodeOptions[masterId] || {};
            if (masterOptions.clusterAuthMode === "x509") {
                print("AwaitLastStableRecoveryTimestamp: authenticating on separate shell " +
                      "with x509 for " + id);
                const subShellArgs = [
                    'mongo',
                    '--ssl',
                    '--sslCAFile=' + masterOptions.sslCAFile,
                    '--sslPEMKeyFile=' + masterOptions.sslPEMKeyFile,
                    '--sslAllowInvalidHostnames',
                    '--authenticationDatabase=$external',
                    '--authenticationMechanism=MONGODB-X509',
                    master.host,
                    '--eval',
                    `(${appendOplogNoteFn.toString()})();`
                ];

                const retVal = _runMongoProgram(...subShellArgs);
                assert.eq(retVal, 0, 'mongo shell did not succeed with exit code 0');
            } else {
                if (masterOptions.clusterAuthMode) {
                    print("AwaitLastStableRecoveryTimestamp: authenticating with " +
                          masterOptions.clusterAuthMode + " for " + id);
                }
                asCluster(master, appendOplogNoteFn, masterOptions.keyFile);
            }
        }

        print("AwaitLastStableRecoveryTimestamp: Beginning for " + id);

        let replSetStatus = assert.commandWorked(master.adminCommand("replSetGetStatus"));
        if (replSetStatus["configsvr"]) {
            // Performing dummy replicated writes against a configsvr is hard, especially if auth
            // is also enabled.
            return;
        }

        rst.awaitNodesAgreeOnPrimary();
        master = rst.getPrimary();

        print("AwaitLastStableRecoveryTimestamp: ensuring the commit point advances for " + id);
        advanceCommitPoint(master);

        print("AwaitLastStableRecoveryTimestamp: Waiting for stable recovery timestamps for " + id);

        assert.soonNoExcept(function() {
            for (let node of rst.nodes) {
                // The `lastStableRecoveryTimestamp` field contains a stable timestamp guaranteed to
                // exist on storage engine recovery to stable timestamp.
                let res = assert.commandWorked(node.adminCommand({replSetGetStatus: 1}));

                // Continue if we're connected to an arbiter.
                if (res.myState === ReplSetTest.State.ARBITER) {
                    continue;
                }

                // A missing `lastStableRecoveryTimestamp` field indicates that the storage
                // engine does not support `recover to a stable timestamp`.
                //
                // A null `lastStableRecoveryTimestamp` indicates that the storage engine supports
                // "recover to a stable timestamp", but does not have a stable recovery timestamp
                // yet.
                if (res.hasOwnProperty("lastStableRecoveryTimestamp") &&
                    res.lastStableRecoveryTimestamp.getTime() === 0) {
                    print("AwaitLastStableRecoveryTimestamp: " + node.host +
                          " does not have a stable recovery timestamp yet.");
                    return false;
                }

                // The `lastStableCheckpointTimestamp` field was added in v4.0, then deprecated and
                // replaced in v4.2 with `lastStableRecoveryTimestamp`. So we check it, too, for
                // backwards compatibility with v4.0 mongods.
                if (res.hasOwnProperty("lastStableCheckpointTimestamp") &&
                    res.lastStableCheckpointTimestamp.getTime() === 0) {
                    print("AwaitLastStableRecoveryTimestamp: " + node.host +
                          " does not have a stable recovery (checkpoint) timestamp yet.");
                    return false;
                }
            }

            return true;
        }, "Not all members have a stable recovery timestamp");

        print("AwaitLastStableRecoveryTimestamp: A stable recovery timestamp has successfully " +
              "established on " + id);
    },
        "awaitReplication" : function(timeout, secondaryOpTimeType, slaves) {
        if (slaves !== undefined && slaves !== self._slaves) {
            print("ReplSetTest awaitReplication: going to check only " + slaves.map(s => s.host));
        }

        timeout = timeout || self.kDefaultTimeoutMS;

        secondaryOpTimeType = secondaryOpTimeType || ReplSetTest.OpTimeType.LAST_APPLIED;

        var masterLatestOpTime;

        // Blocking call, which will wait for the last optime written on the master to be available
        var awaitLastOpTimeWrittenFn = function() {
            var master = self.getPrimary();
            assert.soonNoExcept(function() {
                try {
                    masterLatestOpTime = _getLastOpTime(master);
                } catch (e) {
                    print("ReplSetTest caught exception " + e);
                    return false;
                }

                return true;
            }, "awaiting oplog query", timeout);
        };

        awaitLastOpTimeWrittenFn();

        // get the latest config version from master (with a few retries in case of error)
        var masterConfigVersion;
        var masterName;
        var master;
        var num_attempts = 3;

        assert.retryNoExcept(() => {
            master = this.getPrimary();
            masterConfigVersion = this.getReplSetConfigFromNode().version;
            masterName = master.host;
            return true;
        }, "ReplSetTest awaitReplication: couldnt get repl set config.", num_attempts, 1000);

        print("ReplSetTest awaitReplication: starting: optime for primary, " + masterName +
              ", is " + tojson(masterLatestOpTime));

        let nodesCaughtUp = false;
        let slavesToCheck = slaves || self._slaves;
        let nodeProgress = Array(slavesToCheck.length);

        const Progress = Object.freeze({
            Skip: 'Skip',
            CaughtUp: 'CaughtUp',
            InProgress: 'InProgress',
            Stuck: 'Stuck',
            ConfigMismatch: 'ConfigMismatch'
        });

        function checkProgressSingleNode(index, secondaryCount) {
            var slave = slavesToCheck[index];
            var slaveName = slave.host;

            var slaveConfigVersion = slave.getDB("local")['system.replset'].findOne().version;

            if (masterConfigVersion != slaveConfigVersion) {
                print("ReplSetTest awaitReplication: secondary #" + secondaryCount + ", " +
                      slaveName + ", has config version #" + slaveConfigVersion +
                      ", but expected config version #" + masterConfigVersion);

                if (slaveConfigVersion > masterConfigVersion) {
                    master = self.getPrimary();
                    masterConfigVersion = master.getDB("local")['system.replset'].findOne().version;
                    masterName = master.host;

                    print("ReplSetTest awaitReplication: optime for primary, " + masterName +
                          ", is " + tojson(masterLatestOpTime));
                }

                return Progress.ConfigMismatch;
            }

            // Skip this node if we're connected to an arbiter
            var res = assert.commandWorked(slave.adminCommand({replSetGetStatus: 1}));
            if (res.myState == ReplSetTest.State.ARBITER) {
                return Progress.Skip;
            }

            print("ReplSetTest awaitReplication: checking secondary #" + secondaryCount + ": " +
                  slaveName);

            slave.getDB("admin").getMongo().setSecondaryOk();

            var slaveOpTime;
            if (secondaryOpTimeType == ReplSetTest.OpTimeType.LAST_DURABLE) {
                slaveOpTime = _getDurableOpTime(slave);
            } else {
                slaveOpTime = _getLastOpTime(slave);
            }

            // If the node doesn't have a valid opTime, it likely hasn't received any writes from
            // the primary yet.
            if (!rs.isValidOpTime(slaveOpTime)) {
                print("ReplSetTest awaitReplication: optime for secondary #" + secondaryCount +
                      ", " + slaveName + ", is " + tojson(slaveOpTime) + ", which is NOT valid.");
                return Progress.Stuck;
            }

            // See if the node made progress. We count it as progress even if the node's last optime
            // went backwards because that means the node is in rollback.
            let madeProgress =
                (nodeProgress[index] && (rs.compareOpTimes(nodeProgress[index], slaveOpTime) != 0));
            nodeProgress[index] = slaveOpTime;

            if (rs.compareOpTimes(masterLatestOpTime, slaveOpTime) < 0) {
                masterLatestOpTime = _getLastOpTime(master);
                print("ReplSetTest awaitReplication: optime for " + slaveName +
                      " is newer, resetting latest primary optime to " +
                      tojson(masterLatestOpTime) + ". Also resetting awaitReplication timeout");
                return Progress.InProgress;
            }

            if (!friendlyEqual(masterLatestOpTime, slaveOpTime)) {
                print("ReplSetTest awaitReplication: optime for secondary #" + secondaryCount +
                      ", " + slaveName + ", is " + tojson(slaveOpTime) + " but latest is " +
                      tojson(masterLatestOpTime));
                print("ReplSetTest awaitReplication: secondary #" + secondaryCount + ", " +
                      slaveName + ", is NOT synced");

                // Reset the timeout if a node makes progress, but isn't caught up yet.
                if (madeProgress) {
                    print("ReplSetTest awaitReplication: secondary #" + secondaryCount + ", " +
                          slaveName + ", has made progress. Resetting awaitReplication timeout");
                    return Progress.InProgress;
                }
                return Progress.Stuck;
            }

            print("ReplSetTest awaitReplication: secondary #" + secondaryCount + ", " + slaveName +
                  ", is synced");
            return Progress.CaughtUp;
        }

        // We will reset the timeout if a nodes makes progress, but still isn't caught up yet.
        while (!nodesCaughtUp) {
            assert.soonNoExcept(function() {
                try {
                    print("ReplSetTest awaitReplication: checking secondaries against latest " +
                          "primary optime " + tojson(masterLatestOpTime));
                    var secondaryCount = 0;

                    for (var i = 0; i < slavesToCheck.length; i++) {
                        const action = checkProgressSingleNode(i, secondaryCount);

                        switch (action) {
                            case Progress.CaughtUp:
                                // We only need to increment the secondaryCount if this node is
                                // caught up.
                                secondaryCount++;
                                continue;
                            case Progress.Skip:
                                // Don't increment secondaryCount because this node is an arbiter.
                                continue;
                            case Progress.InProgress:
                                return true;
                            case Progress.Stuck:
                            case Progress.ConfigMismatch:
                                return false;
                            default:
                                throw Error("invalid action: " + tojson(action));
                        }
                    }

                    print("ReplSetTest awaitReplication: finished: all " + secondaryCount +
                          " secondaries synced at optime " + tojson(masterLatestOpTime));
                    nodesCaughtUp = true;
                    return true;
                } catch (e) {
                    print("ReplSetTest awaitReplication: caught exception " + e);

                    // We might have a new master now
                    awaitLastOpTimeWrittenFn();

                    print("ReplSetTest awaitReplication: resetting: optime for primary " +
                          self._master + " is " + tojson(masterLatestOpTime));

                    return false;
                }
            }, "awaiting replication", timeout);
        }
    },
        "waitForAllIndexBuildsToFinish" : function(dbName, collName) {
        // Run a no-op command and wait for it to be applied on secondaries. Due to the asynchronous
        // completion nature of indexes on secondaries, we can guarantee an index build is complete
        // on all secondaries once all secondaries have applied this collMod command.
        assert.commandWorked(this.getPrimary().getDB(dbName).runCommand({collMod: collName}));
        this.awaitReplication();
    },
        "getHashesUsingSessions" : function(sessions, dbName, {
        filterCapped: filterCapped = true,
        filterMapReduce: filterMapReduce = true,
        readAtClusterTime,
    } = {}) {
        return sessions.map(session => {
            const commandObj = {dbHash: 1};
            if (readAtClusterTime !== undefined) {
                commandObj.$_internalReadAtClusterTime = readAtClusterTime;
            }

            const db = session.getDatabase(dbName);
            const res = assert.commandWorked(db.runCommand(commandObj));

            // The "capped" field in the dbHash command response is new as of MongoDB 4.0.
            const cappedCollections = new Set(filterCapped ? res.capped : []);

            for (let collName of Object.keys(res.collections)) {
                // Capped collections are not necessarily truncated at the same points across
                // replica set members and may therefore not have the same md5sum. We remove them
                // from the dbHash command response to avoid an already known case of a mismatch.
                // See SERVER-16049 for more details.
                //
                // If a map-reduce operation is interrupted by the server stepping down, then an
                // unreplicated "tmp.mr." collection may be left behind. We remove it from the
                // dbHash command response to avoid an already known case of a mismatch.
                // TODO SERVER-27147: Stop filtering out "tmp.mr." collections.
                if (cappedCollections.has(collName) ||
                    (filterMapReduce && collName.startsWith("tmp.mr."))) {
                    delete res.collections[collName];
                    // The "uuids" field in the dbHash command response is new as of MongoDB 4.0.
                    if (res.hasOwnProperty("uuids")) {
                        delete res.uuids[collName];
                    }
                }
            }

            return res;
        });
    },
        "getCollectionDiffUsingSessions" : function(
        primarySession, secondarySession, dbName, collNameOrUUID, readAtClusterTime) {
        function PeekableCursor(cursor) {
            let _stashedDoc;

            this.hasNext = function hasNext() {
                return cursor.hasNext();
            };

            this.peekNext = function peekNext() {
                if (_stashedDoc === undefined) {
                    _stashedDoc = cursor.next();
                }
                return _stashedDoc;
            };

            this.next = function next() {
                const result = (_stashedDoc === undefined) ? cursor.next() : _stashedDoc;
                _stashedDoc = undefined;
                return result;
            };
        }

        const docsWithDifferentContents = [];
        const docsMissingOnPrimary = [];
        const docsMissingOnSecondary = [];

        const primaryDB = primarySession.getDatabase(dbName);
        const secondaryDB = secondarySession.getDatabase(dbName);

        const commandObj = {find: collNameOrUUID, sort: {_id: 1}};
        if (readAtClusterTime !== undefined) {
            commandObj.$_internalReadAtClusterTime = readAtClusterTime;
        }

        const primaryCursor =
            new PeekableCursor(new DBCommandCursor(primaryDB, primaryDB.runCommand(commandObj)));

        const secondaryCursor = new PeekableCursor(
            new DBCommandCursor(secondaryDB, secondaryDB.runCommand(commandObj)));

        while (primaryCursor.hasNext() && secondaryCursor.hasNext()) {
            const primaryDoc = primaryCursor.peekNext();
            const secondaryDoc = secondaryCursor.peekNext();

            if (bsonBinaryEqual(primaryDoc, secondaryDoc)) {
                // The same document was found on the primary and secondary so we just move on to
                // the next document for both cursors.
                primaryCursor.next();
                secondaryCursor.next();
                continue;
            }

            const ordering = bsonWoCompare({_: primaryDoc._id}, {_: secondaryDoc._id});
            if (ordering === 0) {
                // The documents have the same _id but have different contents.
                docsWithDifferentContents.push({primary: primaryDoc, secondary: secondaryDoc});
                primaryCursor.next();
                secondaryCursor.next();
            } else if (ordering < 0) {
                // The primary's next document has a smaller _id than the secondary's next document.
                // Since we are iterating the documents in ascending order by their _id, we'll never
                // see a document with 'primaryDoc._id' on the secondary.
                docsMissingOnSecondary.push(primaryDoc);
                primaryCursor.next();
            } else if (ordering > 0) {
                // The primary's next document has a larger _id than the secondary's next document.
                // Since we are iterating the documents in ascending order by their _id, we'll never
                // see a document with 'secondaryDoc._id' on the primary.
                docsMissingOnPrimary.push(secondaryDoc);
                secondaryCursor.next();
            }
        }

        while (primaryCursor.hasNext()) {
            // We've exhausted the secondary's cursor already, so everything remaining from the
            // primary's cursor must be missing from secondary.
            docsMissingOnSecondary.push(primaryCursor.next());
        }

        while (secondaryCursor.hasNext()) {
            // We've exhausted the primary's cursor already, so everything remaining from the
            // secondary's cursor must be missing from primary.
            docsMissingOnPrimary.push(secondaryCursor.next());
        }

        return {docsWithDifferentContents, docsMissingOnPrimary, docsMissingOnSecondary};
    },
        "getHashes" : function(dbName, slaves) {
        assert.neq(dbName, 'local', 'Cannot run getHashes() on the "local" database');

        // _determineLiveSlaves() repopulates both 'self._slaves' and 'self._master'. If we're
        // passed an explicit set of slaves we don't want to do that.
        slaves = slaves || _determineLiveSlaves();

        const sessions = [
            this._master,
            ...slaves.filter(conn => {
                return !conn.adminCommand({isMaster: 1}).arbiterOnly;
            })
        ].map(conn => conn.getDB('test').getSession());

        // getHashes() is sometimes called for versions of MongoDB earlier than 4.0 so we cannot use
        // the dbHash command directly to filter out capped collections. checkReplicatedDataHashes()
        // uses the listCollections command after awaiting replication to determine if a collection
        // is capped.
        const hashes = this.getHashesUsingSessions(sessions, dbName, {filterCapped: false});
        return {master: hashes[0], slaves: hashes.slice(1)};
    },
        "findOplog" : function(conn, query, limit) {
        return conn.getDB('local')
            .getCollection(oplogName)
            .find(query)
            .sort({$natural: -1})
            .limit(limit);
    },
        "dumpOplog" : function(conn, query = {}, limit = 10) {
        var log = 'Dumping the latest ' + limit + ' documents that match ' + tojson(query) +
            ' from the oplog ' + oplogName + ' of ' + conn.host;
        let entries = [];
        let cursor = this.findOplog(conn, query, limit);
        cursor.forEach(function(entry) {
            log = log + '\n' + tojsononeline(entry);
            entries.push(entry);
        });
        jsTestLog(log);
        return entries;
    },
        "checkReplicaSet" : function(checkerFunction, slaves, ...checkerFunctionArgs) {
        assert.eq(typeof checkerFunction,
                  "function",
                  "Expected checkerFunction parameter to be a function");

        // Call getPrimary to populate rst with information about the nodes.
        var primary = this.getPrimary();
        assert(primary, 'calling getPrimary() failed');
        slaves = slaves || self._slaves;

        // Since we cannot determine if there is a background index in progress (SERVER-26624), we
        // use the "collMod" command to wait for any index builds that may be in progress on the
        // primary or on one of the secondaries to complete.
        for (let dbName of primary.getDBNames()) {
            if (dbName === "local") {
                continue;
            }

            let dbHandle = primary.getDB(dbName);
            dbHandle.getCollectionInfos({$or: [{type: "collection"}, {type: {$exists: false}}]})
                .forEach(function(collInfo) {
                    // Skip system collections. We handle here rather than in the getCollectionInfos
                    // filter to take advantage of the fact that a simple 'collection' filter will
                    // skip view evaluation, and therefore won't fail on an invalid view.
                    if (!collInfo.name.startsWith('system.')) {
                        // We intentionally await replication without doing any I/O to avoid any
                        // overhead. We call awaitReplication() later on to ensure the collMod
                        // is replicated to all nodes.
                        try {
                            assert.commandWorked(dbHandle.runCommand({collMod: collInfo.name}));
                        } catch (e) {
                            // Ignore NamespaceNotFound errors because a background thread could
                            // have dropped the collection after getCollectionInfos but before
                            // running collMod.
                            if (e.code != ErrorCodes.NamespaceNotFound) {
                                throw e;
                            }
                        }
                    }
                });
        }

        var activeException = false;

        // Lock the primary to prevent the TTL monitor from deleting expired documents in
        // the background while we are getting the dbhashes of the replica set members. It's not
        // important if the storage engine fails to perform its fsync operation. The only
        // requirement is that writes are locked out.
        assert.commandWorked(primary.adminCommand({fsync: 1, lock: 1, allowFsyncFailure: true}),
                             'failed to lock the primary');
        try {
            this.awaitReplication(null, null, slaves);
            checkerFunction.apply(this, checkerFunctionArgs);
        } catch (e) {
            activeException = true;
            throw e;
        } finally {
            // Allow writes on the primary.
            var res = primary.adminCommand({fsyncUnlock: 1});

            if (!res.ok) {
                var msg = 'failed to unlock the primary, which may cause this' +
                    ' test to hang: ' + tojson(res);
                if (activeException) {
                    print(msg);
                } else {
                    throw new Error(msg);
                }
            }
        }
    },
        "checkReplicatedDataHashes" : function(
        msgPrefix = 'checkReplicatedDataHashes', excludedDBs = [], ignoreUUIDs = false) {
        // Return items that are in either Array `a` or `b` but not both. Note that this will
        // not work with arrays containing NaN. Array.indexOf(NaN) will always return -1.

        var collectionPrinted = new Set();

        function arraySymmetricDifference(a, b) {
            var inAOnly = a.filter(function(elem) {
                return b.indexOf(elem) < 0;
            });

            var inBOnly = b.filter(function(elem) {
                return a.indexOf(elem) < 0;
            });

            return inAOnly.concat(inBOnly);
        }

        function checkDBHashesForReplSet(rst, dbBlacklist = [], slaves, msgPrefix, ignoreUUIDs) {
            // We don't expect the local database to match because some of its
            // collections are not replicated.
            dbBlacklist.push('local');
            slaves = slaves || rst._slaves;

            var success = true;
            var hasDumpedOplog = false;

            // Use '_master' instead of getPrimary() to avoid the detection of a new primary.
            // '_master' must have been populated.
            var primary = rst._master;
            var combinedDBs = new Set(primary.getDBNames());
            const replSetConfig = rst.getReplSetConfigFromNode();

            print("checkDBHashesForReplSet checking data hashes against primary: " + primary.host);

            slaves.forEach(node => {
                // Arbiters have no replicated data.
                if (isNodeArbiter(node)) {
                    print("checkDBHashesForReplSet skipping data of arbiter: " + node.host);
                    return;
                }
                print("checkDBHashesForReplSet going to check data hashes on secondary: " +
                      node.host);
                node.getDBNames().forEach(dbName => combinedDBs.add(dbName));
            });

            for (var dbName of combinedDBs) {
                if (Array.contains(dbBlacklist, dbName)) {
                    continue;
                }

                const dbHashes = rst.getHashes(dbName, slaves);
                const primaryDBHash = dbHashes.master;
                const primaryCollections = Object.keys(primaryDBHash.collections);
                assert.commandWorked(primaryDBHash);

                // Filter only collections that were retrieved by the dbhash. listCollections
                // may include non-replicated collections like system.profile.
                const primaryCollInfos = new CollInfos(primary, 'primary', dbName);
                primaryCollInfos.filter(primaryCollections);

                dbHashes.slaves.forEach(secondaryDBHash => {
                    assert.commandWorked(secondaryDBHash);

                    var secondary = secondaryDBHash._mongo;
                    var secondaryCollections = Object.keys(secondaryDBHash.collections);
                    // Check that collection information is consistent on the primary and
                    // secondaries.
                    const secondaryCollInfos = new CollInfos(secondary, 'secondary', dbName);
                    secondaryCollInfos.filter(secondaryCollections);

                    if (primaryCollections.length !== secondaryCollections.length) {
                        print(
                            msgPrefix +
                            ', the primary and secondary have a different number of collections: ' +
                            tojson(dbHashes));
                        for (var diffColl of arraySymmetricDifference(primaryCollections,
                                                                      secondaryCollections)) {
                            DataConsistencyChecker.dumpCollectionDiff(this,
                                                                      collectionPrinted,
                                                                      primaryCollInfos,
                                                                      secondaryCollInfos,
                                                                      diffColl);
                        }
                        success = false;
                    }

                    const nonCappedCollNames = primaryCollInfos.getNonCappedCollNames();
                    // Only compare the dbhashes of non-capped collections because capped
                    // collections are not necessarily truncated at the same points
                    // across replica set members.
                    nonCappedCollNames.forEach(collName => {
                        if (primaryDBHash.collections[collName] !==
                            secondaryDBHash.collections[collName]) {
                            print(msgPrefix +
                                  ', the primary and secondary have a different hash for the' +
                                  ' collection ' + dbName + '.' + collName + ': ' +
                                  tojson(dbHashes));
                            DataConsistencyChecker.dumpCollectionDiff(this,
                                                                      collectionPrinted,
                                                                      primaryCollInfos,
                                                                      secondaryCollInfos,
                                                                      collName);
                            success = false;
                        }
                    });

                    secondaryCollInfos.collInfosRes.forEach(secondaryInfo => {
                        primaryCollInfos.collInfosRes.forEach(primaryInfo => {
                            if (secondaryInfo.name === primaryInfo.name &&
                                secondaryInfo.type === primaryInfo.type) {
                                if (ignoreUUIDs) {
                                    print(msgPrefix + ", skipping UUID check for " +
                                          primaryInfo.name);
                                    primaryInfo.info.uuid = null;
                                    secondaryInfo.info.uuid = null;
                                }

                                // Ignore the 'flags' collection option as it was removed in 4.2
                                primaryInfo.options.flags = null;
                                secondaryInfo.options.flags = null;

                                if (!bsonBinaryEqual(secondaryInfo, primaryInfo)) {
                                    print(msgPrefix +
                                          ', the primary and secondary have different ' +
                                          'attributes for the collection or view ' + dbName + '.' +
                                          secondaryInfo.name);
                                    DataConsistencyChecker.dumpCollectionDiff(this,
                                                                              collectionPrinted,
                                                                              primaryCollInfos,
                                                                              secondaryCollInfos,
                                                                              secondaryInfo.name);
                                    success = false;
                                }
                            }
                        });
                    });

                    // Check that the following collection stats are the same across replica set
                    // members:
                    //  capped
                    //  nindexes, except on nodes with buildIndexes: false
                    //  ns
                    const hasSecondaryIndexes =
                        replSetConfig.members[rst.getNodeId(secondary)].buildIndexes !== false;
                    primaryCollections.forEach(collName => {
                        var primaryCollStats =
                            primary.getDB(dbName).runCommand({collStats: collName});
                        var secondaryCollStats =
                            secondary.getDB(dbName).runCommand({collStats: collName});

                        if (primaryCollStats.ok !== 1 || secondaryCollStats.ok !== 1) {
                            primaryCollInfos.print(collectionPrinted, collName);
                            secondaryCollInfos.print(collectionPrinted, collName);
                            success = false;
                        } else if (primaryCollStats.capped !== secondaryCollStats.capped ||
                                   (hasSecondaryIndexes &&
                                    primaryCollStats.nindexes !== secondaryCollStats.nindexes) ||
                                   primaryCollStats.ns !== secondaryCollStats.ns) {
                            print(msgPrefix +
                                  ', the primary and secondary have different stats for the ' +
                                  'collection ' + dbName + '.' + collName);
                            DataConsistencyChecker.dumpCollectionDiff(this,
                                                                      collectionPrinted,
                                                                      primaryCollInfos,
                                                                      secondaryCollInfos,
                                                                      collName);
                            success = false;
                        }
                    });

                    if (nonCappedCollNames.length === primaryCollections.length) {
                        // If the primary and secondary have the same hashes for all the
                        // collections in the database and there aren't any capped collections,
                        // then the hashes for the whole database should match.
                        if (primaryDBHash.md5 !== secondaryDBHash.md5) {
                            print(msgPrefix +
                                  ', the primary and secondary have a different hash for ' +
                                  'the ' + dbName + ' database: ' + tojson(dbHashes));
                            success = false;
                        }
                    }

                    if (!success) {
                        if (!hasDumpedOplog) {
                            print("checkDBHashesForReplSet dumping oplogs from all nodes");
                            this.dumpOplog(primary, {}, 100);
                            rst.getSecondaries().forEach(secondary =>
                                                             this.dumpOplog(secondary, {}, 100));
                            hasDumpedOplog = true;
                        }
                    }
                });
            }

            assert(success, 'dbhash mismatch between primary and secondary');
        }

        var liveSlaves = _determineLiveSlaves();
        this.checkReplicaSet(checkDBHashesForReplSet,
                             liveSlaves,
                             this,
                             excludedDBs,
                             liveSlaves,
                             msgPrefix,
                             ignoreUUIDs);
    },
        "checkOplogs" : function(msgPrefix) {
        var liveSlaves = _determineLiveSlaves();
        this.checkReplicaSet(checkOplogs, liveSlaves, this, liveSlaves, msgPrefix);
    },
        "checkCollectionCounts" : function(msgPrefix = 'checkCollectionCounts') {
        let success = true;
        const errPrefix = `${msgPrefix}, counts did not match for collection`;

        function checkCollectionCount(coll) {
            const itCount = coll.find().itcount();
            const fastCount = coll.count();
            if (itCount !== fastCount) {
                print(`${errPrefix} ${coll.getFullName()} on ${coll.getMongo().host}.` +
                      ` itcount: ${itCount}, fast count: ${fastCount}`);
                print("Collection info: " +
                      tojson(coll.getDB().getCollectionInfos({name: coll.getName()})));
                print("Collection stats: " + tojson(coll.stats()));
                print("First 10 documents in collection: " +
                      tojson(coll.find().limit(10).toArray()));

                // TODO (SERVER-35483): Remove this block and enable fastcount checks.
                if (coll.getFullName() == "config.transactions") {
                    print(`Ignoring fastcount error for ${coll.getFullName()} on ` +
                          `${coll.getMongo().host}. itcount: ${itCount}, fast count: ${fastCount}`);
                    return;
                }
                success = false;
            }
        }

        function checkCollectionCountsForDB(_db) {
            const res = assert.commandWorked(
                _db.runCommand({listCollections: 1, includePendingDrops: true}));
            const collNames = new DBCommandCursor(_db, res).toArray();
            collNames.forEach(c => checkCollectionCount(_db.getCollection(c.name)));
        }

        function checkCollectionCountsForNode(node) {
            const dbNames = node.getDBNames();
            dbNames.forEach(dbName => checkCollectionCountsForDB(node.getDB(dbName)));
        }

        function checkCollectionCountsForReplSet(rst) {
            rst.nodes.forEach(node => {
                // Arbiters have no replicated collections.
                if (isNodeArbiter(node)) {
                    print("checkCollectionCounts skipping counts for arbiter: " + node.host);
                    return;
                }
                checkCollectionCountsForNode(node);
            });
            assert(success, `Collection counts did not match. search for '${errPrefix}' in logs.`);
        }

        this.checkReplicaSet(checkCollectionCountsForReplSet, null, this);
    },
        "start" : function(n, options, restart, wait) {
        if (n.length) {
            var nodes = n;
            var started = [];

            for (var i = 0; i < nodes.length; i++) {
                if (this.start(nodes[i], Object.merge({}, options), restart, wait)) {
                    started.push(nodes[i]);
                }
            }

            return started;
        }

        // TODO: should we do something special if we don't currently know about this node?
        n = this.getNodeId(n);

        print("ReplSetTest n is : " + n);

        var defaults = {
            useHostName: this.useHostName,
            oplogSize: this.oplogSize,
            keyFile: this.keyFile,
            port: _useBridge ? _unbridgedPorts[n] : this.ports[n],
            replSet: this.useSeedList ? this.getURL() : this.name,
            dbpath: "$set-$node"
        };

        //
        // Note : this replaces the binVersion of the shared startSet() options the first time
        // through, so the full set is guaranteed to have different versions if size > 1.  If using
        // start() independently, independent version choices will be made
        //
        if (options && options.binVersion) {
            options.binVersion = MongoRunner.versionIterator(options.binVersion);
        }

        // If restarting a node, use its existing options as the defaults.
        var baseOptions;
        if ((options && options.restart) || restart) {
            baseOptions = _useBridge ? _unbridgedNodes[n].fullOptions : this.nodes[n].fullOptions;
        } else {
            baseOptions = defaults;
        }
        baseOptions = Object.merge(baseOptions, this.nodeOptions["n" + n]);
        options = Object.merge(baseOptions, options);
        if (options.hasOwnProperty("rsConfig")) {
            this.nodeOptions["n" + n] =
                Object.merge(this.nodeOptions["n" + n], {rsConfig: options.rsConfig});
        }
        delete options.rsConfig;

        options.restart = options.restart || restart;

        var pathOpts = {node: n, set: this.name};
        options.pathOpts = Object.merge(options.pathOpts || {}, pathOpts);

        // Turn off periodic noop writes for replica sets by default.
        options.setParameter = options.setParameter || {};
        if (typeof (options.setParameter) === "string") {
            var eqIdx = options.setParameter.indexOf("=");
            if (eqIdx != -1) {
                var param = options.setParameter.substring(0, eqIdx);
                var value = options.setParameter.substring(eqIdx + 1);
                options.setParameter = {};
                options.setParameter[param] = value;
            }
        }
        options.setParameter.writePeriodicNoops = options.setParameter.writePeriodicNoops || false;

        // We raise the number of initial sync connect attempts for tests that disallow chaining.
        // Disabling chaining can cause sync source selection to take longer so we must increase
        // the number of connection attempts.
        options.setParameter.numInitialSyncConnectAttempts =
            options.setParameter.numInitialSyncConnectAttempts || 60;

        if (tojson(options) != tojson({}))
            printjson(options);

        print("ReplSetTest " + (restart ? "(Re)" : "") + "Starting....");

        if (_useBridge && (restart === undefined || !restart)) {
            // We leave the mongobridge process running when the mongod process is restarted so we
            // don't need to start a new one.
            var bridgeOptions = Object.merge(_bridgeOptions, options.bridgeOptions || {});
            bridgeOptions = Object.merge(bridgeOptions, {
                hostName: this.host,
                port: this.ports[n],
                // The mongod processes identify themselves to mongobridge as host:port, where the
                // host is the actual hostname of the machine and not localhost.
                dest: getHostName() + ":" + _unbridgedPorts[n],
            });

            if (jsTestOptions().networkMessageCompressors) {
                bridgeOptions["networkMessageCompressors"] =
                    jsTestOptions().networkMessageCompressors;
            }

            this.nodes[n] = new MongoBridge(bridgeOptions);
        }

        var conn = MongoRunner.runMongod(options);
        if (!conn) {
            throw new Error("Failed to start node " + n);
        }

        // Make sure to call _addPath, otherwise folders won't be cleaned.
        this._addPath(conn.dbpath);

        if (_useBridge) {
            this.nodes[n].connectToBridge();
            _unbridgedNodes[n] = conn;
        } else {
            this.nodes[n] = conn;
        }

        // Add replica set specific attributes.
        this.nodes[n].nodeId = n;

        printjson(this.nodes);

        // Clean up after noReplSet to ensure it doesn't effect future restarts.
        if (options.noReplSet) {
            this.nodes[n].fullOptions.replSet = defaults.replSet;
            delete this.nodes[n].fullOptions.noReplSet;
        }

        wait = wait || false;
        if (!wait.toFixed) {
            if (wait)
                wait = 0;
            else
                wait = -1;
        }

        if (wait >= 0) {
            // Wait for node to start up.
            _waitForHealth(this.nodes[n], Health.UP, wait);
        }

        if (_causalConsistency) {
            this.nodes[n].setCausalConsistency(true);
        }

        return this.nodes[n];
    },
        "restart" : function(n, options, signal, wait) {
        // Can specify wait as third parameter, if using default signal
        if (signal == true || signal == false) {
            wait = signal;
            signal = undefined;
        }

        this.stop(n, signal, options, {forRestart: true});

        var started = this.start(n, options, true, wait);

        if (jsTestOptions().keyFile) {
            if (started.length) {
                // if n was an array of conns, start will return an array of connections
                for (var i = 0; i < started.length; i++) {
                    assert(jsTest.authenticate(started[i]), "Failed authentication during restart");
                }
            } else {
                assert(jsTest.authenticate(started), "Failed authentication during restart");
            }
        }
        return started;
    },
        "freeze" : function(node, ...wrappedArgs) {
            if (node.hasOwnProperty('length')) {
                let returnValueList = [];
                for (let i = 0; i < node.length; i++) {
                    returnValueList.push(wrapped.call(this, node[i], ...wrappedArgs));
                }

                return returnValueList;
            }

            return wrapped.call(this, node, ...wrappedArgs);
        },
        "stopMaster" : function(signal, opts) {
        var master = this.getPrimary();
        var master_id = this.getNodeId(master);
        return this.stop(master_id, signal, opts);
    },
        "stop" : function(n, signal, opts, {forRestart: forRestart = false} = {}) {
        // Flatten array of nodes to stop
        if (n.length) {
            var nodes = n;

            var stopped = [];
            for (var i = 0; i < nodes.length; i++) {
                if (this.stop(nodes[i], signal, opts))
                    stopped.push(nodes[i]);
            }

            return stopped;
        }

        // Can specify wait as second parameter, if using default signal
        if (signal == true || signal == false) {
            signal = undefined;
        }

        n = this.getNodeId(n);

        var conn = _useBridge ? _unbridgedNodes[n] : this.nodes[n];
        print('ReplSetTest stop *** Shutting down mongod in port ' + conn.port + ' ***');
        var ret = MongoRunner.stopMongod(conn, signal, opts);

        print('ReplSetTest stop *** Mongod in port ' + conn.port + ' shutdown with code (' + ret +
              ') ***');

        if (_useBridge && !forRestart) {
            // We leave the mongobridge process running when the mongod process is being restarted.
            const bridge = this.nodes[n];
            print('ReplSetTest stop *** Shutting down mongobridge on port ' + bridge.port + ' ***');
            const exitCode = bridge.stop();  // calls MongoBridge#stop()
            print('ReplSetTest stop *** mongobridge on port ' + bridge.port +
                  ' exited with code (' + exitCode + ') ***');
        }

        return ret;
    },
        "stopSet" : function(signal, forRestart, opts) {
        // Check to make sure data is the same on all nodes.
        if (!jsTest.options().skipCheckDBHashes) {
            print("ReplSetTest stopSet going to run data consistency checks.");
            // To skip this check add TestData.skipCheckDBHashes = true;
            // Reasons to skip this test include:
            // - the primary goes down and none can be elected (so fsync lock/unlock commands fail)
            // - the replica set is in an unrecoverable inconsistent state. E.g. the replica set
            //   is partitioned.
            //
            let master = _callIsMaster();
            if (master && this._liveNodes.length > 1) {  // skip for sets with 1 live node
                // Auth only on live nodes because authutil.assertAuthenticate
                // refuses to log in live connections if some secondaries are down.
                print("ReplSetTest stopSet checking oplogs.");
                asCluster(this._liveNodes, () => this.checkOplogs());
                print("ReplSetTest stopSet checking replicated data hashes.");
                asCluster(this._liveNodes, () => this.checkReplicatedDataHashes());
            } else {
                print(
                    "ReplSetTest stopSet skipped data consistency checks. Number of _liveNodes: " +
                    this._liveNodes.length + ", _callIsMaster response: " + master);
            }
            print("ReplSetTest stopSet finished data consistency checks.");
        }

        // Make shutdown faster in tests, especially when election handoff has no viable candidate.
        // Ignore errors from setParameter, perhaps it's a pre-4.1.10 mongod.
        if (_callIsMaster()) {
            asCluster(this._liveNodes, () => {
                for (let node of this._liveNodes) {
                    try {
                        print(
                            "ReplSetTest stopSet disabling 'waitForStepDownOnNonCommandShutdown' on " +
                            node.host);
                        assert.commandWorked(node.adminCommand({
                            setParameter: 1,
                            waitForStepDownOnNonCommandShutdown: false,
                        }));
                    } catch (e) {
                        print("Error in setParameter for waitForStepDownOnNonCommandShutdown:");
                        print(e);
                    }
                }
            });
        }

        print("ReplSetTest stopSet stopping all replica set nodes.");
        for (var i = 0; i < this.ports.length; i++) {
            this.stop(i, signal, opts);
        }
        print("ReplSetTest stopSet stopped all replica set nodes.");

        if (forRestart) {
            print("ReplSetTest stopSet returning since forRestart=true.");
            return;
        }

        if ((!opts || !opts.noCleanData) && _alldbpaths) {
            print("ReplSetTest stopSet deleting all dbpaths");
            for (var i = 0; i < _alldbpaths.length; i++) {
                print("ReplSetTest stopSet deleting dbpath: " + _alldbpaths[i]);
                resetDbpath(_alldbpaths[i]);
            }
            print("ReplSetTest stopSet deleted all dbpaths");
        }

        _forgetReplSet(this.name);

        print('ReplSetTest stopSet *** Shut down repl set - test worked ****');
    },
        "usesBridge" : function() {
        return _useBridge;
    },
        "waitForState" : function(node, state, timeout, reconnectNode) {
        _waitForIndicator(node, state, "state", timeout, reconnectNode);
    },
        "waitForMaster" : function(timeout) {
        var master;
        assert.soonNoExcept(function() {
            return (master = self.getPrimary());
        }, "waiting for master", timeout);

        return master;
    },
        "name" : "EquipoReplicaSet",
        "useHostName" : true,
        "host" : "LT-CMARINS",
        "oplogSize" : 40,
        "useSeedList" : false,
        "keyFile" : undefined,
        "protocolVersion" : undefined,
        "waitForKeys" : undefined,
        "nodeOptions" : {
                "n0" : undefined,
                "n1" : undefined,
                "n2" : undefined
        },
        "nodes" : [ ],
        "ports" : [
                20000,
                20001,
                20002
        ]
}
> EquipoReplicaSet.startSet()
ReplSetTest starting set
ReplSetTest n is : 0
{
        "useHostName" : true,
        "oplogSize" : 40,
        "keyFile" : undefined,
        "port" : 20000,
        "replSet" : "EquipoReplicaSet",
        "dbpath" : "$set-$node",
        "restart" : undefined,
        "pathOpts" : {
                "node" : 0,
                "set" : "EquipoReplicaSet"
        },
        "setParameter" : {
                "writePeriodicNoops" : false,
                "numInitialSyncConnectAttempts" : 60
        }
}
ReplSetTest Starting....
Resetting db path '/data/db/EquipoReplicaSet-0'
2024-05-24T21:59:26.038-0500 I  -        [js] shell: started program (sh25800):  C:\Program Files\MongoDB\Server\4.2\bin\mongod.exe --oplogSize 40 --port 20000 --replSet EquipoReplicaSet --dbpath /data/db/EquipoReplicaSet-0 --setParameter writePeriodicNoops=false --setParameter numInitialSyncConnectAttempts=60 --bind_ip 0.0.0.0 --setParameter enableTestCommands=1 --setParameter disableLogicalSessionCacheRefresh=true --setParameter minNumChunksForSessionsCollection=1 --setParameter orphanCleanupDelaySecs=1
d20000| 2024-05-24T21:59:26.065-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
d20000| 2024-05-24T21:59:26.397-0500 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] MongoDB starting : pid=25800 port=20000 dbpath=/data/db/EquipoReplicaSet-0 64-bit host=LT-CMARINS
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] targetMinOS: Windows 7/Windows Server 2008 R2
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] db version v4.2.25
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] git version: 41b59c2bfb5121e66f18cc3ef40055a1b5fb6c2e
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] allocator: tcmalloc
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] modules: none
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] build environment:
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten]     distmod: 2012plus
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten]     distarch: x86_64
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten]     target_arch: x86_64
d20000| 2024-05-24T21:59:26.401-0500 I  CONTROL  [initandlisten] options: { net: { bindIp: "0.0.0.0", port: 20000 }, replication: { oplogSizeMB: 40, replSet: "EquipoReplicaSet" }, setParameter: { disableLogicalSessionCacheRefresh: "true", enableTestCommands: "1", minNumChunksForSessionsCollection: "1", numInitialSyncConnectAttempts: "60", orphanCleanupDelaySecs: "1", writePeriodicNoops: "false" }, storage: { dbPath: "/data/db/EquipoReplicaSet-0" } }
d20000| 2024-05-24T21:59:26.404-0500 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=11623M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
d20000| 2024-05-24T21:59:26.447-0500 I  STORAGE  [initandlisten] WiredTiger message [1716605966:447936][25800:140705395791968], txn-recover: Set global recovery timestamp: (0, 0)
d20000| 2024-05-24T21:59:26.454-0500 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
d20000| 2024-05-24T21:59:26.463-0500 I  STORAGE  [initandlisten] Timestamp monitor starting
d20000| 2024-05-24T21:59:26.475-0500 I  CONTROL  [initandlisten]
d20000| 2024-05-24T21:59:26.475-0500 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
d20000| 2024-05-24T21:59:26.475-0500 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
d20000| 2024-05-24T21:59:26.475-0500 I  CONTROL  [initandlisten]
d20000| 2024-05-24T21:59:26.480-0500 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
d20000| 2024-05-24T21:59:26.481-0500 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 376a9025-c61b-4420-b37b-12c7d9ebee58 and options: { capped: true, size: 10485760 }
d20000| 2024-05-24T21:59:26.495-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
d20000| 2024-05-24T21:59:26.799-0500 W  FTDC     [initandlisten] Failed to initialize Performance Counters for FTDC: WindowsPdhError: PdhExpandCounterPathW failed with 'El objeto especificado no se encontr├│ en el equipo.' for counter '\Processor(_Total)\% Idle Time'
d20000| 2024-05-24T21:59:26.799-0500 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/EquipoReplicaSet-0/diagnostic.data'
d20000| 2024-05-24T21:59:26.809-0500 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: c1f9cc37-4916-4eb6-a76c-928daa7f83ae and options: {}
d20000| 2024-05-24T21:59:26.816-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
d20000| 2024-05-24T21:59:26.816-0500 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: b8d9fada-5458-4833-a1b9-1f8bd6d2f4bf and options: {}
d20000| 2024-05-24T21:59:26.823-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
d20000| 2024-05-24T21:59:26.824-0500 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 01568d01-fb9c-40d5-9e9a-442bfe0bd682 and options: {}
d20000| 2024-05-24T21:59:26.830-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
d20000| 2024-05-24T21:59:26.832-0500 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
d20000| 2024-05-24T21:59:26.832-0500 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
d20000| 2024-05-24T21:59:26.832-0500 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: f78dfc29-bd38-4ea2-b72c-28cb927b970c and options: {}
d20000| 2024-05-24T21:59:26.840-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
d20000| 2024-05-24T21:59:26.841-0500 I  REPL     [initandlisten] Initialized the rollback ID to 1
d20000| 2024-05-24T21:59:26.841-0500 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
d20000| 2024-05-24T21:59:26.842-0500 I  NETWORK  [listener] Listening on 0.0.0.0
d20000| 2024-05-24T21:59:26.842-0500 I  NETWORK  [listener] waiting for connections on port 20000
d20000| 2024-05-24T21:59:27.057-0500 I  NETWORK  [listener] connection accepted from 127.0.0.1:65090 #1 (1 connection now open)
d20000| 2024-05-24T21:59:27.059-0500 I  NETWORK  [conn1] received client metadata from 127.0.0.1:65090 conn1: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
[ connection to LT-CMARINS:20000 ]
ReplSetTest n is : 1
{
        "useHostName" : true,
        "oplogSize" : 40,
        "keyFile" : undefined,
        "port" : 20001,
        "replSet" : "EquipoReplicaSet",
        "dbpath" : "$set-$node",
        "restart" : undefined,
        "pathOpts" : {
                "node" : 1,
                "set" : "EquipoReplicaSet"
        },
        "setParameter" : {
                "writePeriodicNoops" : false,
                "numInitialSyncConnectAttempts" : 60
        }
}
ReplSetTest Starting....
Resetting db path '/data/db/EquipoReplicaSet-1'
2024-05-24T21:59:27.069-0500 I  -        [js] shell: started program (sh20464):  C:\Program Files\MongoDB\Server\4.2\bin\mongod.exe --oplogSize 40 --port 20001 --replSet EquipoReplicaSet --dbpath /data/db/EquipoReplicaSet-1 --setParameter writePeriodicNoops=false --setParameter numInitialSyncConnectAttempts=60 --bind_ip 0.0.0.0 --setParameter enableTestCommands=1 --setParameter disableLogicalSessionCacheRefresh=true --setParameter minNumChunksForSessionsCollection=1 --setParameter orphanCleanupDelaySecs=1
d20001| 2024-05-24T21:59:27.109-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
d20001| 2024-05-24T21:59:27.402-0500 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] MongoDB starting : pid=20464 port=20001 dbpath=/data/db/EquipoReplicaSet-1 64-bit host=LT-CMARINS
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] targetMinOS: Windows 7/Windows Server 2008 R2
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] db version v4.2.25
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] git version: 41b59c2bfb5121e66f18cc3ef40055a1b5fb6c2e
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] allocator: tcmalloc
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] modules: none
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] build environment:
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten]     distmod: 2012plus
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten]     distarch: x86_64
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten]     target_arch: x86_64
d20001| 2024-05-24T21:59:27.404-0500 I  CONTROL  [initandlisten] options: { net: { bindIp: "0.0.0.0", port: 20001 }, replication: { oplogSizeMB: 40, replSet: "EquipoReplicaSet" }, setParameter: { disableLogicalSessionCacheRefresh: "true", enableTestCommands: "1", minNumChunksForSessionsCollection: "1", numInitialSyncConnectAttempts: "60", orphanCleanupDelaySecs: "1", writePeriodicNoops: "false" }, storage: { dbPath: "/data/db/EquipoReplicaSet-1" } }
d20001| 2024-05-24T21:59:27.409-0500 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=11623M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
d20001| 2024-05-24T21:59:27.448-0500 I  STORAGE  [initandlisten] WiredTiger message [1716605967:448039][20464:140705395791968], txn-recover: Set global recovery timestamp: (0, 0)
d20001| 2024-05-24T21:59:27.457-0500 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
d20001| 2024-05-24T21:59:27.463-0500 I  STORAGE  [initandlisten] Timestamp monitor starting
d20001| 2024-05-24T21:59:27.476-0500 I  CONTROL  [initandlisten]
d20001| 2024-05-24T21:59:27.476-0500 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
d20001| 2024-05-24T21:59:27.476-0500 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
d20001| 2024-05-24T21:59:27.476-0500 I  CONTROL  [initandlisten]
d20001| 2024-05-24T21:59:27.478-0500 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
d20001| 2024-05-24T21:59:27.481-0500 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 5f153ef3-697b-4152-a3d5-578c859a914e and options: { capped: true, size: 10485760 }
d20001| 2024-05-24T21:59:27.491-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
d20001| 2024-05-24T21:59:27.661-0500 W  FTDC     [initandlisten] Failed to initialize Performance Counters for FTDC: WindowsPdhError: PdhExpandCounterPathW failed with 'El objeto especificado no se encontr├│ en el equipo.' for counter '\Memory\Available Bytes'
d20001| 2024-05-24T21:59:27.661-0500 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/EquipoReplicaSet-1/diagnostic.data'
d20001| 2024-05-24T21:59:27.668-0500 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 017b353a-a066-442d-854d-6515dfc6fa7c and options: {}
d20001| 2024-05-24T21:59:27.674-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
d20001| 2024-05-24T21:59:27.675-0500 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 2a9abe9e-46f8-4976-9c65-0bd14713b7c5 and options: {}
d20001| 2024-05-24T21:59:27.686-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
d20001| 2024-05-24T21:59:27.687-0500 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: 31d99b65-4048-4f8c-9000-ee021af7468b and options: {}
d20001| 2024-05-24T21:59:27.697-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
d20001| 2024-05-24T21:59:27.697-0500 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
d20001| 2024-05-24T21:59:27.697-0500 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
d20001| 2024-05-24T21:59:27.697-0500 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 1e13369d-2d33-4ea7-ab23-3bae75e776ea and options: {}
d20001| 2024-05-24T21:59:27.708-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
d20001| 2024-05-24T21:59:27.708-0500 I  REPL     [initandlisten] Initialized the rollback ID to 1
d20001| 2024-05-24T21:59:27.708-0500 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
d20001| 2024-05-24T21:59:27.715-0500 I  NETWORK  [listener] Listening on 0.0.0.0
d20001| 2024-05-24T21:59:27.715-0500 I  NETWORK  [listener] waiting for connections on port 20001
d20001| 2024-05-24T21:59:28.098-0500 I  NETWORK  [listener] connection accepted from 127.0.0.1:65091 #1 (1 connection now open)
d20001| 2024-05-24T21:59:28.100-0500 I  NETWORK  [conn1] received client metadata from 127.0.0.1:65091 conn1: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
[ connection to LT-CMARINS:20000, connection to LT-CMARINS:20001 ]
ReplSetTest n is : 2
{
        "useHostName" : true,
        "oplogSize" : 40,
        "keyFile" : undefined,
        "port" : 20002,
        "replSet" : "EquipoReplicaSet",
        "dbpath" : "$set-$node",
        "restart" : undefined,
        "pathOpts" : {
                "node" : 2,
                "set" : "EquipoReplicaSet"
        },
        "setParameter" : {
                "writePeriodicNoops" : false,
                "numInitialSyncConnectAttempts" : 60
        }
}
ReplSetTest Starting....
Resetting db path '/data/db/EquipoReplicaSet-2'
2024-05-24T21:59:28.110-0500 I  -        [js] shell: started program (sh12400):  C:\Program Files\MongoDB\Server\4.2\bin\mongod.exe --oplogSize 40 --port 20002 --replSet EquipoReplicaSet --dbpath /data/db/EquipoReplicaSet-2 --setParameter writePeriodicNoops=false --setParameter numInitialSyncConnectAttempts=60 --bind_ip 0.0.0.0 --setParameter enableTestCommands=1 --setParameter disableLogicalSessionCacheRefresh=true --setParameter minNumChunksForSessionsCollection=1 --setParameter orphanCleanupDelaySecs=1
d20002| 2024-05-24T21:59:28.140-0500 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
d20002| 2024-05-24T21:59:28.505-0500 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] MongoDB starting : pid=12400 port=20002 dbpath=/data/db/EquipoReplicaSet-2 64-bit host=LT-CMARINS
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] targetMinOS: Windows 7/Windows Server 2008 R2
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] db version v4.2.25
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] git version: 41b59c2bfb5121e66f18cc3ef40055a1b5fb6c2e
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] allocator: tcmalloc
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] modules: none
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] build environment:
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten]     distmod: 2012plus
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten]     distarch: x86_64
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten]     target_arch: x86_64
d20002| 2024-05-24T21:59:28.511-0500 I  CONTROL  [initandlisten] options: { net: { bindIp: "0.0.0.0", port: 20002 }, replication: { oplogSizeMB: 40, replSet: "EquipoReplicaSet" }, setParameter: { disableLogicalSessionCacheRefresh: "true", enableTestCommands: "1", minNumChunksForSessionsCollection: "1", numInitialSyncConnectAttempts: "60", orphanCleanupDelaySecs: "1", writePeriodicNoops: "false" }, storage: { dbPath: "/data/db/EquipoReplicaSet-2" } }
d20002| 2024-05-24T21:59:28.527-0500 I  STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=11623M,cache_overflow=(file_max=0M),session_max=33000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000,close_scan_interval=10,close_handle_minimum=250),statistics_log=(wait=0),verbose=[recovery_progress,checkpoint_progress],
d20002| 2024-05-24T21:59:28.558-0500 I  STORAGE  [initandlisten] WiredTiger message [1716605968:557508][12400:140705395791968], txn-recover: Set global recovery timestamp: (0, 0)
d20002| 2024-05-24T21:59:28.563-0500 I  RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
d20002| 2024-05-24T21:59:28.569-0500 I  STORAGE  [initandlisten] Timestamp monitor starting
d20002| 2024-05-24T21:59:28.571-0500 I  CONTROL  [initandlisten]
d20002| 2024-05-24T21:59:28.572-0500 I  CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
d20002| 2024-05-24T21:59:28.572-0500 I  CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
d20002| 2024-05-24T21:59:28.572-0500 I  CONTROL  [initandlisten]
d20002| 2024-05-24T21:59:28.573-0500 I  STORAGE  [initandlisten] Flow Control is enabled on this deployment.
d20002| 2024-05-24T21:59:28.573-0500 I  STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: 92b11f4c-2947-4672-8cbe-642e83ee9ac1 and options: { capped: true, size: 10485760 }
d20002| 2024-05-24T21:59:28.578-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.startup_log
d20002| 2024-05-24T21:59:28.739-0500 W  FTDC     [initandlisten] Failed to initialize Performance Counters for FTDC: WindowsPdhError: PdhExpandCounterPathW failed with 'El objeto especificado no se encontr├│ en el equipo.' for counter '\Memory\Available Bytes'
d20002| 2024-05-24T21:59:28.739-0500 I  FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/EquipoReplicaSet-2/diagnostic.data'
d20002| 2024-05-24T21:59:28.743-0500 I  STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 1435321e-0c81-493c-ada8-bc068480d5a8 and options: {}
d20002| 2024-05-24T21:59:28.754-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.oplogTruncateAfterPoint
d20002| 2024-05-24T21:59:28.754-0500 I  STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: 3ff1aba4-b0ec-4ae4-8120-e6b61b3dba14 and options: {}
d20002| 2024-05-24T21:59:28.761-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.minvalid
d20002| 2024-05-24T21:59:28.761-0500 I  STORAGE  [initandlisten] createCollection: local.replset.election with generated UUID: c66f9c00-cbf8-4854-a09e-5e410425167d and options: {}
d20002| 2024-05-24T21:59:28.770-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.replset.election
d20002| 2024-05-24T21:59:28.770-0500 I  REPL     [initandlisten] Did not find local initialized voted for document at startup.
d20002| 2024-05-24T21:59:28.770-0500 I  REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
d20002| 2024-05-24T21:59:28.771-0500 I  STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 706b9eed-d5c2-4cd0-883d-1f5f727ce45f and options: {}
d20002| 2024-05-24T21:59:28.778-0500 I  INDEX    [initandlisten] index build: done building index _id_ on ns local.system.rollback.id
d20002| 2024-05-24T21:59:28.778-0500 I  REPL     [initandlisten] Initialized the rollback ID to 1
d20002| 2024-05-24T21:59:28.778-0500 I  REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
d20002| 2024-05-24T21:59:28.784-0500 I  NETWORK  [listener] Listening on 0.0.0.0
d20002| 2024-05-24T21:59:28.785-0500 I  NETWORK  [listener] waiting for connections on port 20002
d20002| 2024-05-24T21:59:29.138-0500 I  NETWORK  [listener] connection accepted from 127.0.0.1:65092 #1 (1 connection now open)
d20002| 2024-05-24T21:59:29.148-0500 I  NETWORK  [conn1] received client metadata from 127.0.0.1:65092 conn1: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
[
        connection to LT-CMARINS:20000,
        connection to LT-CMARINS:20001,
        connection to LT-CMARINS:20002
]
[
        connection to LT-CMARINS:20000,
        connection to LT-CMARINS:20001,
        connection to LT-CMARINS:20002
]
> EquipoReplicaSet.initiate()
{
        "replSetInitiate" : {
                "_id" : "EquipoReplicaSet",
                "protocolVersion" : 1,
                "members" : [
                        {
                                "_id" : 0,
                                "host" : "LT-CMARINS:20000"
                        }
                ]
        }
}
d20000| 2024-05-24T21:59:36.955-0500 I  REPL     [conn1] replSetInitiate admin command received from client
d20000| 2024-05-24T21:59:36.965-0500 I  REPL     [conn1] replSetInitiate config object with 1 members parses ok
d20000| 2024-05-24T21:59:36.966-0500 I  REPL     [conn1] ******
d20000| 2024-05-24T21:59:36.966-0500 I  REPL     [conn1] creating replication oplog of size: 40MB...
d20000| 2024-05-24T21:59:36.966-0500 I  STORAGE  [conn1] createCollection: local.oplog.rs with generated UUID: e6ae7098-fa7a-4c71-bb52-d5d0eea11dd2 and options: { capped: true, size: 41943040, autoIndexId: false }
d20000| 2024-05-24T21:59:36.971-0500 I  STORAGE  [conn1] Starting OplogTruncaterThread local.oplog.rs
d20000| 2024-05-24T21:59:36.976-0500 I  STORAGE  [conn1] The size storer reports that the oplog contains 0 records totaling to 0 bytes
d20000| 2024-05-24T21:59:36.976-0500 I  STORAGE  [conn1] Scanning the oplog to determine where to place markers for truncation
d20000| 2024-05-24T21:59:36.976-0500 I  STORAGE  [conn1] WiredTiger record store oplog processing took 0ms
d20000| 2024-05-24T21:59:36.994-0500 I  REPL     [conn1] ******
d20000| 2024-05-24T21:59:36.995-0500 I  STORAGE  [conn1] createCollection: local.system.replset with generated UUID: 28cda437-744c-48ae-a6c4-28dcf96ee7c9 and options: {}
d20000| 2024-05-24T21:59:37.005-0500 I  INDEX    [conn1] index build: done building index _id_ on ns local.system.replset
d20000| 2024-05-24T21:59:37.009-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "replset.election" }
d20000| 2024-05-24T21:59:37.009-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "system.replset" }
d20000| 2024-05-24T21:59:37.009-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "startup_log" }
d20000| 2024-05-24T21:59:37.009-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "replset.minvalid" }
d20000| 2024-05-24T21:59:37.010-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "replset.oplogTruncateAfterPoint" }
d20000| 2024-05-24T21:59:37.010-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "oplog.rs" }
d20000| 2024-05-24T21:59:37.010-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "system.rollback.id" }
d20000| 2024-05-24T21:59:37.010-0500 I  STORAGE  [conn1] createCollection: admin.system.version with provided UUID: 67799212-f019-4291-bd12-2052fd2dc314 and options: { uuid: UUID("67799212-f019-4291-bd12-2052fd2dc314") }
d20000| 2024-05-24T21:59:37.020-0500 I  INDEX    [conn1] index build: done building index _id_ on ns admin.system.version
d20000| 2024-05-24T21:59:37.020-0500 I  COMMAND  [conn1] setting featureCompatibilityVersion to 4.2
d20000| 2024-05-24T21:59:37.020-0500 I  NETWORK  [conn1] Skip closing connection for connection # 1
d20000| 2024-05-24T21:59:37.022-0500 I  REPL     [conn1] New replica set config in use: { _id: "EquipoReplicaSet", version: 1, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "LT-CMARINS:20000", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('66515418742a19a3a6f6c58e') } }
d20000| 2024-05-24T21:59:37.022-0500 I  REPL     [conn1] This node is LT-CMARINS:20000 in the config
d20000| 2024-05-24T21:59:37.022-0500 I  REPL     [conn1] transition to STARTUP2 from STARTUP
d20000| 2024-05-24T21:59:37.023-0500 I  REPL     [conn1] Starting replication storage threads
d20000| 2024-05-24T21:59:37.028-0500 I  REPL     [conn1] transition to RECOVERING from STARTUP2
d20000| 2024-05-24T21:59:37.029-0500 I  REPL     [conn1] Starting replication fetcher thread
d20000| 2024-05-24T21:59:37.032-0500 I  REPL     [conn1] Starting replication applier thread
d20000| 2024-05-24T21:59:37.032-0500 I  REPL     [conn1] Starting replication reporter thread
d20000| 2024-05-24T21:59:37.032-0500 I  REPL     [rsSync-0] Starting oplog application
d20000| 2024-05-24T21:59:37.041-0500 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
d20000| 2024-05-24T21:59:37.044-0500 I  ELECTION [rsSync-0] conducting a dry run election to see if we could be elected. current term: 0
d20000| 2024-05-24T21:59:37.044-0500 I  ELECTION [replexec-0] dry election run succeeded, running for election in term 1
d20000| 2024-05-24T21:59:37.047-0500 I  ELECTION [replexec-0] election succeeded, assuming primary role in term 1
d20000| 2024-05-24T21:59:37.047-0500 I  REPL     [replexec-0] transition to PRIMARY from SECONDARY
d20000| 2024-05-24T21:59:37.047-0500 I  REPL     [replexec-0] Resetting sync source to empty, which was :27017
d20000| 2024-05-24T21:59:37.047-0500 I  REPL     [replexec-0] Entering primary catch-up mode.
d20000| 2024-05-24T21:59:37.047-0500 I  REPL     [replexec-0] Exited primary catch-up mode.
d20000| 2024-05-24T21:59:37.047-0500 I  REPL     [replexec-0] Stopping replication producer
d20000| 2024-05-24T21:59:37.047-0500 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 1
d20000| 2024-05-24T21:59:37.049-0500 I  REPL     [RstlKillOpThread] Starting to kill user operations
d20000| 2024-05-24T21:59:37.049-0500 I  REPL     [RstlKillOpThread] Stopped killing user operations
d20000| 2024-05-24T21:59:37.049-0500 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
d20000| 2024-05-24T21:59:37.051-0500 I  STORAGE  [rsSync-0] createCollection: config.transactions with generated UUID: ce769838-2aca-4b9f-bdf8-e7d23b080471 and options: {}
d20000| 2024-05-24T21:59:37.061-0500 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.transactions
d20000| 2024-05-24T21:59:37.061-0500 I  STORAGE  [rsSync-0] createCollection: config.image_collection with generated UUID: 3fe8c628-800f-4731-82f6-e135ab5c0ad6 and options: {}
d20000| 2024-05-24T21:59:37.072-0500 I  INDEX    [rsSync-0] index build: done building index _id_ on ns config.image_collection
d20000| 2024-05-24T21:59:37.073-0500 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
d20000| 2024-05-24T21:59:37.075-0500 I  STORAGE  [monitoring-keys-for-HMAC] createCollection: admin.system.keys with generated UUID: cddf1501-58bf-4a48-b523-9b73349f494c and options: {}
d20000| 2024-05-24T21:59:37.084-0500 I  INDEX    [monitoring-keys-for-HMAC] index build: done building index _id_ on ns admin.system.keys
d20000| 2024-05-24T21:59:37.086-0500 I  STORAGE  [monitoring-keys-for-HMAC] Triggering the first stable checkpoint. Initial Data: Timestamp(1716605977, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1716605977, 7)
Reconfiguring replica set to add in other nodes
{
        "replSetReconfig" : {
                "_id" : "EquipoReplicaSet",
                "protocolVersion" : 1,
                "members" : [
                        {
                                "_id" : 0,
                                "host" : "LT-CMARINS:20000"
                        },
                        {
                                "_id" : 1,
                                "host" : "LT-CMARINS:20001"
                        },
                        {
                                "_id" : 2,
                                "host" : "LT-CMARINS:20002"
                        }
                ],
                "version" : 2
        }
}
d20000| 2024-05-24T21:59:37.244-0500 I  REPL     [conn1] replSetReconfig admin command received from client; new config: { _id: "EquipoReplicaSet", protocolVersion: 1.0, members: [ { _id: 0.0, host: "LT-CMARINS:20000" }, { _id: 1.0, host: "LT-CMARINS:20001" }, { _id: 2.0, host: "LT-CMARINS:20002" } ], version: 2.0 }
d20001| 2024-05-24T21:59:37.250-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65093 #2 (2 connections now open)
d20001| 2024-05-24T21:59:37.251-0500 I  NETWORK  [conn2] end connection 192.168.101.72:65093 (1 connection now open)
d20002| 2024-05-24T21:59:37.252-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65094 #2 (2 connections now open)
d20000| 2024-05-24T21:59:37.252-0500 I  REPL     [conn1] replSetReconfig config object with 3 members parses ok
d20002| 2024-05-24T21:59:37.252-0500 I  NETWORK  [conn2] end connection 192.168.101.72:65094 (1 connection now open)
d20000| 2024-05-24T21:59:37.252-0500 I  REPL     [conn1] Scheduling remote command request for reconfig quorum check: RemoteCommand 1 -- target:LT-CMARINS:20001 db:admin cmd:{ replSetHeartbeat: "EquipoReplicaSet", configVersion: 2, hbv: 1, from: "LT-CMARINS:20000", fromId: 0, term: 1 }
d20000| 2024-05-24T21:59:37.253-0500 I  REPL     [conn1] Scheduling remote command request for reconfig quorum check: RemoteCommand 2 -- target:LT-CMARINS:20002 db:admin cmd:{ replSetHeartbeat: "EquipoReplicaSet", configVersion: 2, hbv: 1, from: "LT-CMARINS:20000", fromId: 0, term: 1 }
d20000| 2024-05-24T21:59:37.253-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20001
d20000| 2024-05-24T21:59:37.254-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20002
d20001| 2024-05-24T21:59:37.255-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65095 #3 (2 connections now open)
d20002| 2024-05-24T21:59:37.256-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65096 #3 (2 connections now open)
d20001| 2024-05-24T21:59:37.256-0500 I  NETWORK  [conn3] received client metadata from 192.168.101.72:65095 conn3: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20002| 2024-05-24T21:59:37.256-0500 I  NETWORK  [conn3] received client metadata from 192.168.101.72:65096 conn3: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20002| 2024-05-24T21:59:37.259-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20000
d20001| 2024-05-24T21:59:37.259-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20000
d20000| 2024-05-24T21:59:37.259-0500 I  REPL     [conn1] New replica set config in use: { _id: "EquipoReplicaSet", version: 2, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "LT-CMARINS:20000", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "LT-CMARINS:20001", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "LT-CMARINS:20002", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('66515418742a19a3a6f6c58e') } }
d20000| 2024-05-24T21:59:37.259-0500 I  REPL     [conn1] This node is LT-CMARINS:20000 in the config
d20000| 2024-05-24T21:59:37.260-0500 I  REPL     [replexec-1] Member LT-CMARINS:20001 is now in state STARTUP
d20000| 2024-05-24T21:59:37.260-0500 I  REPL     [replexec-0] Member LT-CMARINS:20002 is now in state STARTUP
d20000| 2024-05-24T21:59:37.266-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65098 #6 (2 connections now open)
d20000| 2024-05-24T21:59:37.270-0500 I  NETWORK  [conn6] received client metadata from 192.168.101.72:65098 conn6: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:37.270-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65097 #7 (3 connections now open)
d20000| 2024-05-24T21:59:37.271-0500 I  NETWORK  [conn7] received client metadata from 192.168.101.72:65097 conn7: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:37.274-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65100 #8 (4 connections now open)
d20000| 2024-05-24T21:59:37.274-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65099 #9 (5 connections now open)
d20000| 2024-05-24T21:59:37.274-0500 I  NETWORK  [conn8] end connection 192.168.101.72:65100 (4 connections now open)
d20000| 2024-05-24T21:59:37.275-0500 I  NETWORK  [conn9] end connection 192.168.101.72:65099 (3 connections now open)
d20001| 2024-05-24T21:59:37.275-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65101 #6 (3 connections now open)
d20002| 2024-05-24T21:59:37.280-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65102 #6 (3 connections now open)
d20001| 2024-05-24T21:59:37.286-0500 I  NETWORK  [conn6] end connection 192.168.101.72:65101 (2 connections now open)
d20002| 2024-05-24T21:59:37.290-0500 I  NETWORK  [conn6] end connection 192.168.101.72:65102 (2 connections now open)
d20001| 2024-05-24T21:59:37.290-0500 I  STORAGE  [replexec-1] createCollection: local.system.replset with generated UUID: b286cba9-945b-465f-ab0b-d5fbfa627704 and options: {}
d20002| 2024-05-24T21:59:37.291-0500 I  STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: 0acd377a-00ad-4615-81b1-c6d48cd8419a and options: {}
d20002| 2024-05-24T21:59:37.300-0500 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.system.replset
d20001| 2024-05-24T21:59:37.301-0500 I  INDEX    [replexec-1] index build: done building index _id_ on ns local.system.replset
d20002| 2024-05-24T21:59:37.301-0500 I  REPL     [replexec-0] New replica set config in use: { _id: "EquipoReplicaSet", version: 2, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "LT-CMARINS:20000", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "LT-CMARINS:20001", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "LT-CMARINS:20002", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('66515418742a19a3a6f6c58e') } }
d20001| 2024-05-24T21:59:37.301-0500 I  REPL     [replexec-1] New replica set config in use: { _id: "EquipoReplicaSet", version: 2, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 0, host: "LT-CMARINS:20000", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 1, host: "LT-CMARINS:20001", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "LT-CMARINS:20002", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('66515418742a19a3a6f6c58e') } }
d20001| 2024-05-24T21:59:37.302-0500 I  REPL     [replexec-1] This node is LT-CMARINS:20001 in the config
d20001| 2024-05-24T21:59:37.302-0500 I  REPL     [replexec-1] transition to STARTUP2 from STARTUP
d20002| 2024-05-24T21:59:37.302-0500 I  REPL     [replexec-0] This node is LT-CMARINS:20002 in the config
d20002| 2024-05-24T21:59:37.302-0500 I  REPL     [replexec-0] transition to STARTUP2 from STARTUP
d20001| 2024-05-24T21:59:37.305-0500 I  REPL     [replexec-1] Starting replication storage threads
d20001| 2024-05-24T21:59:37.305-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20002
d20002| 2024-05-24T21:59:37.305-0500 I  REPL     [replexec-0] Starting replication storage threads
d20002| 2024-05-24T21:59:37.305-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20001
d20002| 2024-05-24T21:59:37.306-0500 I  REPL     [replexec-1] Member LT-CMARINS:20000 is now in state PRIMARY
d20002| 2024-05-24T21:59:37.307-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65104 #9 (3 connections now open)
d20001| 2024-05-24T21:59:37.306-0500 I  REPL     [replexec-0] Member LT-CMARINS:20000 is now in state PRIMARY
d20001| 2024-05-24T21:59:37.307-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65103 #9 (3 connections now open)
d20002| 2024-05-24T21:59:37.307-0500 I  NETWORK  [conn9] received client metadata from 192.168.101.72:65104 conn9: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20002| 2024-05-24T21:59:37.308-0500 I  REPL     [replexec-2] Member LT-CMARINS:20001 is now in state STARTUP2
d20001| 2024-05-24T21:59:37.307-0500 I  NETWORK  [conn9] received client metadata from 192.168.101.72:65103 conn9: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20001| 2024-05-24T21:59:37.308-0500 I  REPL     [replexec-2] Member LT-CMARINS:20002 is now in state STARTUP2
d20001| 2024-05-24T21:59:37.310-0500 I  STORAGE  [replexec-1] createCollection: local.temp_oplog_buffer with generated UUID: 3ad59f5c-5549-4f99-8d30-25d4ed1bd7d4 and options: { temp: true }
d20002| 2024-05-24T21:59:37.310-0500 I  STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: 38cf79fb-040c-4d72-ba89-c3c469c969b2 and options: { temp: true }
d20001| 2024-05-24T21:59:37.328-0500 I  INDEX    [replexec-1] index build: done building index _id_ on ns local.temp_oplog_buffer
d20001| 2024-05-24T21:59:37.331-0500 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
d20001| 2024-05-24T21:59:37.331-0500 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (3ad59f5c-5549-4f99-8d30-25d4ed1bd7d4).
d20002| 2024-05-24T21:59:37.333-0500 I  INDEX    [replexec-0] index build: done building index _id_ on ns local.temp_oplog_buffer
d20002| 2024-05-24T21:59:37.333-0500 I  INITSYNC [replication-0] Starting initial sync (attempt 1 of 10)
d20002| 2024-05-24T21:59:37.334-0500 I  STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (38cf79fb-040c-4d72-ba89-c3c469c969b2).
d20001| 2024-05-24T21:59:37.351-0500 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: 902b97e4-bd90-4723-aae3-0802d8229a11 and options: { temp: true }
d20002| 2024-05-24T21:59:37.352-0500 I  STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: fb362e27-2ff1-4c5d-b2b8-14934c2991c7 and options: { temp: true }
d20001| 2024-05-24T21:59:37.379-0500 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
d20001| 2024-05-24T21:59:37.400-0500 I  REPL     [replication-0] waiting for 2 pings from other members before syncing
d20002| 2024-05-24T21:59:37.424-0500 I  INDEX    [replication-0] index build: done building index _id_ on ns local.temp_oplog_buffer
d20002| 2024-05-24T21:59:37.454-0500 I  REPL     [replication-1] waiting for 2 pings from other members before syncing
d20001| 2024-05-24T21:59:38.400-0500 I  REPL     [replication-1] sync source candidate: LT-CMARINS:20000
d20001| 2024-05-24T21:59:38.400-0500 I  INITSYNC [replication-1] Initial syncer oplog truncation finished in: 0ms
d20001| 2024-05-24T21:59:38.400-0500 I  REPL     [replication-1] ******
d20001| 2024-05-24T21:59:38.400-0500 I  REPL     [replication-1] creating replication oplog of size: 40MB...
d20001| 2024-05-24T21:59:38.400-0500 I  STORAGE  [replication-1] createCollection: local.oplog.rs with generated UUID: 69382e62-3941-4b6f-94c5-2bc85a09ed89 and options: { capped: true, size: 41943040, autoIndexId: false }
d20001| 2024-05-24T21:59:38.407-0500 I  STORAGE  [replication-1] Starting OplogTruncaterThread local.oplog.rs
d20001| 2024-05-24T21:59:38.407-0500 I  STORAGE  [replication-1] The size storer reports that the oplog contains 0 records totaling to 0 bytes
d20001| 2024-05-24T21:59:38.407-0500 I  STORAGE  [replication-1] Scanning the oplog to determine where to place markers for truncation
d20001| 2024-05-24T21:59:38.408-0500 I  STORAGE  [replication-1] WiredTiger record store oplog processing took 0ms
d20001| 2024-05-24T21:59:38.426-0500 I  REPL     [replication-1] ******
d20001| 2024-05-24T21:59:38.426-0500 I  REPL     [replication-1] dropReplicatedDatabases - dropping 1 databases
d20001| 2024-05-24T21:59:38.426-0500 I  REPL     [replication-1] dropReplicatedDatabases - dropped 1 databases
d20001| 2024-05-24T21:59:38.426-0500 I  CONNPOOL [RS] Connecting to LT-CMARINS:20000
d20000| 2024-05-24T21:59:38.428-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65105 #10 (4 connections now open)
d20000| 2024-05-24T21:59:38.428-0500 I  NETWORK  [conn10] received client metadata from 192.168.101.72:65105 conn10: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.435-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65107 #11 (5 connections now open)
d20000| 2024-05-24T21:59:38.437-0500 I  NETWORK  [conn11] received client metadata from 192.168.101.72:65107 conn11: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.437-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65106 #12 (6 connections now open)
d20000| 2024-05-24T21:59:38.445-0500 I  NETWORK  [conn12] received client metadata from 192.168.101.72:65106 conn12: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20001| 2024-05-24T21:59:38.447-0500 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:admin.system.version
d20000| 2024-05-24T21:59:38.448-0500 I  NETWORK  [conn12] end connection 192.168.101.72:65106 (5 connections now open)
d20001| 2024-05-24T21:59:38.449-0500 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.version with provided UUID: 67799212-f019-4291-bd12-2052fd2dc314 and options: { uuid: UUID("67799212-f019-4291-bd12-2052fd2dc314") }
d20002| 2024-05-24T21:59:38.454-0500 I  REPL     [replication-0] sync source candidate: LT-CMARINS:20000
d20002| 2024-05-24T21:59:38.454-0500 I  INITSYNC [replication-0] Initial syncer oplog truncation finished in: 0ms
d20002| 2024-05-24T21:59:38.454-0500 I  REPL     [replication-0] ******
d20002| 2024-05-24T21:59:38.454-0500 I  REPL     [replication-0] creating replication oplog of size: 40MB...
d20002| 2024-05-24T21:59:38.454-0500 I  STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: 249868cd-8fdc-4743-b8e1-afbbd9b7561a and options: { capped: true, size: 41943040, autoIndexId: false }
d20002| 2024-05-24T21:59:38.458-0500 I  STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
d20002| 2024-05-24T21:59:38.459-0500 I  STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
d20002| 2024-05-24T21:59:38.459-0500 I  STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
d20002| 2024-05-24T21:59:38.459-0500 I  STORAGE  [replication-0] WiredTiger record store oplog processing took 0ms
d20001| 2024-05-24T21:59:38.459-0500 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
d20000| 2024-05-24T21:59:38.460-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65108 #13 (6 connections now open)
d20001| 2024-05-24T21:59:38.459-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20000| 2024-05-24T21:59:38.461-0500 I  NETWORK  [conn13] received client metadata from 192.168.101.72:65108 conn13: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20001| 2024-05-24T21:59:38.465-0500 I  COMMAND  [repl-writer-worker-0] setting featureCompatibilityVersion to 4.2
d20000| 2024-05-24T21:59:38.465-0500 I  NETWORK  [conn13] end connection 192.168.101.72:65108 (5 connections now open)
d20001| 2024-05-24T21:59:38.465-0500 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 9
d20001| 2024-05-24T21:59:38.465-0500 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 3
d20001| 2024-05-24T21:59:38.465-0500 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 1
d20001| 2024-05-24T21:59:38.465-0500 I  INITSYNC [replication-0] CollectionCloner ns:admin.system.version finished cloning with status: OK
d20001| 2024-05-24T21:59:38.468-0500 I  INDEX    [replication-0] index build: inserted 1 keys from external sorter into index in 0 seconds
d20001| 2024-05-24T21:59:38.470-0500 I  INDEX    [replication-0] index build: done building index _id_ on ns admin.system.version
d20001| 2024-05-24T21:59:38.471-0500 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:admin.system.keys
d20001| 2024-05-24T21:59:38.472-0500 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.keys with provided UUID: cddf1501-58bf-4a48-b523-9b73349f494c and options: { uuid: UUID("cddf1501-58bf-4a48-b523-9b73349f494c") }
d20002| 2024-05-24T21:59:38.476-0500 I  REPL     [replication-0] ******
d20002| 2024-05-24T21:59:38.476-0500 I  REPL     [replication-0] dropReplicatedDatabases - dropping 1 databases
d20002| 2024-05-24T21:59:38.476-0500 I  REPL     [replication-0] dropReplicatedDatabases - dropped 1 databases
d20002| 2024-05-24T21:59:38.477-0500 I  CONNPOOL [RS] Connecting to LT-CMARINS:20000
d20000| 2024-05-24T21:59:38.480-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65109 #14 (6 connections now open)
d20000| 2024-05-24T21:59:38.480-0500 I  NETWORK  [conn14] received client metadata from 192.168.101.72:65109 conn14: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.483-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65111 #15 (7 connections now open)
d20000| 2024-05-24T21:59:38.486-0500 I  NETWORK  [conn15] received client metadata from 192.168.101.72:65111 conn15: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.486-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65110 #16 (8 connections now open)
d20000| 2024-05-24T21:59:38.487-0500 I  NETWORK  [conn16] received client metadata from 192.168.101.72:65110 conn16: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.487-0500 I  NETWORK  [conn15] end connection 192.168.101.72:65111 (7 connections now open)
d20002| 2024-05-24T21:59:38.488-0500 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:admin.system.version
d20002| 2024-05-24T21:59:38.488-0500 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.version with provided UUID: 67799212-f019-4291-bd12-2052fd2dc314 and options: { uuid: UUID("67799212-f019-4291-bd12-2052fd2dc314") }
d20001| 2024-05-24T21:59:38.490-0500 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.keys properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.keys" } using method: Hybrid
d20001| 2024-05-24T21:59:38.490-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20000| 2024-05-24T21:59:38.490-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65112 #17 (8 connections now open)
d20000| 2024-05-24T21:59:38.491-0500 I  NETWORK  [conn17] received client metadata from 192.168.101.72:65112 conn17: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.495-0500 I  NETWORK  [conn17] end connection 192.168.101.72:65112 (7 connections now open)
d20001| 2024-05-24T21:59:38.495-0500 I  INITSYNC [replication-1] CollectionCloner ns:admin.system.keys finished cloning with status: OK
d20002| 2024-05-24T21:59:38.496-0500 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } using method: Foreground
d20001| 2024-05-24T21:59:38.496-0500 I  INDEX    [replication-1] index build: inserted 2 keys from external sorter into index in 0 seconds
d20000| 2024-05-24T21:59:38.497-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65113 #18 (8 connections now open)
d20000| 2024-05-24T21:59:38.502-0500 I  NETWORK  [conn18] received client metadata from 192.168.101.72:65113 conn18: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20001| 2024-05-24T21:59:38.497-0500 I  INDEX    [replication-1] index build: done building index _id_ on ns admin.system.keys
d20002| 2024-05-24T21:59:38.496-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20001| 2024-05-24T21:59:38.502-0500 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:config.image_collection
d20001| 2024-05-24T21:59:38.503-0500 I  STORAGE  [repl-writer-worker-0] createCollection: config.image_collection with provided UUID: 3fe8c628-800f-4731-82f6-e135ab5c0ad6 and options: { uuid: UUID("3fe8c628-800f-4731-82f6-e135ab5c0ad6") }
d20002| 2024-05-24T21:59:38.504-0500 I  COMMAND  [repl-writer-worker-0] setting featureCompatibilityVersion to 4.2
d20002| 2024-05-24T21:59:38.504-0500 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 9
d20002| 2024-05-24T21:59:38.504-0500 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 3
d20002| 2024-05-24T21:59:38.504-0500 I  NETWORK  [repl-writer-worker-0] Skip closing connection for connection # 1
d20000| 2024-05-24T21:59:38.504-0500 I  NETWORK  [conn18] end connection 192.168.101.72:65113 (7 connections now open)
d20002| 2024-05-24T21:59:38.504-0500 I  INITSYNC [replication-1] CollectionCloner ns:admin.system.version finished cloning with status: OK
d20002| 2024-05-24T21:59:38.506-0500 I  INDEX    [replication-1] index build: inserted 1 keys from external sorter into index in 0 seconds
d20002| 2024-05-24T21:59:38.507-0500 I  INDEX    [replication-1] index build: done building index _id_ on ns admin.system.version
d20002| 2024-05-24T21:59:38.507-0500 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:admin.system.keys
d20002| 2024-05-24T21:59:38.508-0500 I  STORAGE  [repl-writer-worker-0] createCollection: admin.system.keys with provided UUID: cddf1501-58bf-4a48-b523-9b73349f494c and options: { uuid: UUID("cddf1501-58bf-4a48-b523-9b73349f494c") }
d20001| 2024-05-24T21:59:38.517-0500 I  INDEX    [repl-writer-worker-0] index build: starting on config.image_collection properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.image_collection" } using method: Hybrid
d20001| 2024-05-24T21:59:38.517-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20000| 2024-05-24T21:59:38.518-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65114 #19 (8 connections now open)
d20000| 2024-05-24T21:59:38.519-0500 I  NETWORK  [conn19] received client metadata from 192.168.101.72:65114 conn19: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20002| 2024-05-24T21:59:38.521-0500 I  INDEX    [repl-writer-worker-0] index build: starting on admin.system.keys properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.keys" } using method: Hybrid
d20002| 2024-05-24T21:59:38.521-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20000| 2024-05-24T21:59:38.522-0500 I  NETWORK  [conn19] end connection 192.168.101.72:65114 (7 connections now open)
d20001| 2024-05-24T21:59:38.522-0500 I  INITSYNC [replication-1] CollectionCloner ns:config.image_collection finished cloning with status: OK
d20000| 2024-05-24T21:59:38.522-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65115 #20 (8 connections now open)
d20000| 2024-05-24T21:59:38.523-0500 I  NETWORK  [conn20] received client metadata from 192.168.101.72:65115 conn20: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20001| 2024-05-24T21:59:38.523-0500 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
d20001| 2024-05-24T21:59:38.524-0500 I  INDEX    [replication-1] index build: done building index _id_ on ns config.image_collection
d20000| 2024-05-24T21:59:38.525-0500 I  NETWORK  [conn20] end connection 192.168.101.72:65115 (7 connections now open)
d20002| 2024-05-24T21:59:38.525-0500 I  INITSYNC [replication-0] CollectionCloner ns:admin.system.keys finished cloning with status: OK
d20002| 2024-05-24T21:59:38.526-0500 I  INDEX    [replication-0] index build: inserted 2 keys from external sorter into index in 0 seconds
d20001| 2024-05-24T21:59:38.527-0500 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:config.transactions
d20002| 2024-05-24T21:59:38.528-0500 I  INDEX    [replication-0] index build: done building index _id_ on ns admin.system.keys
d20001| 2024-05-24T21:59:38.528-0500 I  STORAGE  [repl-writer-worker-0] createCollection: config.transactions with provided UUID: ce769838-2aca-4b9f-bdf8-e7d23b080471 and options: { uuid: UUID("ce769838-2aca-4b9f-bdf8-e7d23b080471") }
d20002| 2024-05-24T21:59:38.532-0500 I  INITSYNC [replication-1] CollectionCloner::start called, on ns:config.image_collection
d20002| 2024-05-24T21:59:38.533-0500 I  STORAGE  [repl-writer-worker-0] createCollection: config.image_collection with provided UUID: 3fe8c628-800f-4731-82f6-e135ab5c0ad6 and options: { uuid: UUID("3fe8c628-800f-4731-82f6-e135ab5c0ad6") }
d20001| 2024-05-24T21:59:38.543-0500 I  INDEX    [repl-writer-worker-0] index build: starting on config.transactions properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.transactions" } using method: Hybrid
d20001| 2024-05-24T21:59:38.543-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20000| 2024-05-24T21:59:38.543-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65116 #21 (8 connections now open)
d20000| 2024-05-24T21:59:38.544-0500 I  NETWORK  [conn21] received client metadata from 192.168.101.72:65116 conn21: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.547-0500 I  NETWORK  [conn21] end connection 192.168.101.72:65116 (7 connections now open)
d20001| 2024-05-24T21:59:38.547-0500 I  INITSYNC [replication-0] CollectionCloner ns:config.transactions finished cloning with status: OK
d20002| 2024-05-24T21:59:38.547-0500 I  INDEX    [repl-writer-worker-0] index build: starting on config.image_collection properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.image_collection" } using method: Hybrid
d20002| 2024-05-24T21:59:38.547-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20001| 2024-05-24T21:59:38.548-0500 I  INDEX    [replication-0] index build: inserted 0 keys from external sorter into index in 0 seconds
d20000| 2024-05-24T21:59:38.548-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65117 #22 (8 connections now open)
d20000| 2024-05-24T21:59:38.549-0500 I  NETWORK  [conn22] received client metadata from 192.168.101.72:65117 conn22: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20001| 2024-05-24T21:59:38.549-0500 I  INDEX    [replication-0] index build: done building index _id_ on ns config.transactions
d20002| 2024-05-24T21:59:38.551-0500 I  INITSYNC [replication-0] CollectionCloner ns:config.image_collection finished cloning with status: OK
d20000| 2024-05-24T21:59:38.551-0500 I  NETWORK  [conn22] end connection 192.168.101.72:65117 (7 connections now open)
d20001| 2024-05-24T21:59:38.551-0500 I  INITSYNC [replication-0] Finished cloning data: OK. Beginning oplog replay.
d20001| 2024-05-24T21:59:38.552-0500 I  INITSYNC [replication-1] No need to apply operations. (currently at { : Timestamp(1716605977, 9) })
d20002| 2024-05-24T21:59:38.552-0500 I  INDEX    [replication-0] index build: inserted 0 keys from external sorter into index in 0 seconds
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "replset.oplogTruncateAfterPoint" }
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "system.rollback.id" }
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "replset.minvalid" }
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "replset.election" }
d20002| 2024-05-24T21:59:38.554-0500 I  INDEX    [replication-0] index build: done building index _id_ on ns config.image_collection
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "startup_log" }
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "oplog.rs" }
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "temp_oplog_buffer" }
d20001| 2024-05-24T21:59:38.552-0500 I  COMMAND  [replication-0] CMD: collMod: { collMod: "system.replset" }
d20002| 2024-05-24T21:59:38.556-0500 I  INITSYNC [replication-0] CollectionCloner::start called, on ns:config.transactions
d20002| 2024-05-24T21:59:38.557-0500 I  STORAGE  [repl-writer-worker-0] createCollection: config.transactions with provided UUID: ce769838-2aca-4b9f-bdf8-e7d23b080471 and options: { uuid: UUID("ce769838-2aca-4b9f-bdf8-e7d23b080471") }
d20001| 2024-05-24T21:59:38.554-0500 I  INITSYNC [replication-0] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(0, 0), t: -1 }
d20001| 2024-05-24T21:59:38.554-0500 I  INITSYNC [replication-0] Initial sync attempt finishing up.
d20002| 2024-05-24T21:59:38.569-0500 I  INDEX    [repl-writer-worker-0] index build: starting on config.transactions properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "config.transactions" } using method: Hybrid
d20002| 2024-05-24T21:59:38.569-0500 I  INDEX    [repl-writer-worker-0] build may temporarily use up to 200 megabytes of RAM
d20001| 2024-05-24T21:59:38.554-0500 I  INITSYNC [replication-0] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1716605977328), totalInitialSyncElapsedMillis: 1226, initialSyncAttempts: [], approxTotalDataSize: 229, approxTotalBytesCopied: 229, remainingInitialSyncEstimatedMillis: 0, fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp(1716605977, 9), initialSyncOplogEnd: Timestamp(1716605977, 9), databases: { databasesToClone: 0, databasesCloned: 2, admin: { collections: 2, clonedCollections: 2, start: new Date(1716605978446), end: new Date(1716605978502), elapsedMillis: 56, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, bytesToCopy: 59, approxBytesCopied: 59, start: new Date(1716605978447), end: new Date(1716605978471), elapsedMillis: 24, receivedBatches: 1 }, admin.system.keys: { documentsToCopy: 2, documentsCopied: 2, indexes: 1, fetchedBatches: 1, bytesToCopy: 170, approxBytesCopied: 170, start: new Date(1716605978471), end: new Date(1716605978502), elapsedMillis: 31, receivedBatches: 1 } }, config: { collections: 2, clonedCollections: 2, start: new Date(1716605978502), end: new Date(1716605978551), elapsedMillis: 49, config.image_collection: { documentsToCopy: 0, documentsCopied: 0, indexes: 1, fetchedBatches: 0, bytesToCopy: 0, start: new Date(1716605978502), end: new Date(1716605978527), elapsedMillis: 25, receivedBatches: 0 }, config.transactions: { documentsToCopy: 0, documentsCopied: 0, indexes: 1, fetchedBatches: 0, bytesToCopy: 0, start: new Date(1716605978527), end: new Date(1716605978551), elapsedMillis: 24, receivedBatches: 0 } } } }
d20001| 2024-05-24T21:59:38.554-0500 I  STORAGE  [replication-1] Finishing collection drop for local.temp_oplog_buffer (902b97e4-bd90-4723-aae3-0802d8229a11).
d20001| 2024-05-24T21:59:38.556-0500 I  CONNPOOL [RS] Ending connection to host LT-CMARINS:20000 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
d20001| 2024-05-24T21:59:38.558-0500 I  INITSYNC [replication-1] initial sync done; took 1s.
d20001| 2024-05-24T21:59:38.558-0500 I  REPL     [replication-1] transition to RECOVERING from STARTUP2
d20001| 2024-05-24T21:59:38.558-0500 I  REPL     [replication-1] Starting replication fetcher thread
d20001| 2024-05-24T21:59:38.567-0500 I  REPL     [replication-1] Starting replication applier thread
d20001| 2024-05-24T21:59:38.567-0500 I  REPL     [replication-1] Starting replication reporter thread
d20001| 2024-05-24T21:59:38.567-0500 I  REPL     [rsSync-0] Starting oplog application
d20001| 2024-05-24T21:59:38.567-0500 I  REPL     [rsBackgroundSync] could not find member to sync from
d20002| 2024-05-24T21:59:38.573-0500 I  INITSYNC [replication-1] CollectionCloner ns:config.transactions finished cloning with status: OK
d20000| 2024-05-24T21:59:38.570-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65118 #23 (8 connections now open)
d20001| 2024-05-24T21:59:38.569-0500 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
d20001| 2024-05-24T21:59:38.569-0500 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
d20000| 2024-05-24T21:59:38.570-0500 I  NETWORK  [conn23] received client metadata from 192.168.101.72:65118 conn23: { driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:38.573-0500 I  NETWORK  [conn23] end connection 192.168.101.72:65118 (7 connections now open)
d20002| 2024-05-24T21:59:38.574-0500 I  INDEX    [replication-1] index build: inserted 0 keys from external sorter into index in 0 seconds
d20002| 2024-05-24T21:59:38.575-0500 I  INDEX    [replication-1] index build: done building index _id_ on ns config.transactions
d20002| 2024-05-24T21:59:38.578-0500 I  INITSYNC [replication-1] Finished cloning data: OK. Beginning oplog replay.
d20002| 2024-05-24T21:59:38.579-0500 I  INITSYNC [replication-0] No need to apply operations. (currently at { : Timestamp(1716605977, 9) })
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "system.replset" }
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "replset.oplogTruncateAfterPoint" }
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "oplog.rs" }
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "replset.minvalid" }
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "system.rollback.id" }
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "startup_log" }
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "replset.election" }
d20002| 2024-05-24T21:59:38.579-0500 I  COMMAND  [replication-1] CMD: collMod: { collMod: "temp_oplog_buffer" }
d20002| 2024-05-24T21:59:38.579-0500 I  INITSYNC [replication-0] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime: { ts: Timestamp(0, 0), t: -1 }
d20002| 2024-05-24T21:59:38.579-0500 I  INITSYNC [replication-0] Initial sync attempt finishing up.
d20002| 2024-05-24T21:59:38.580-0500 I  CONNPOOL [RS] Ending connection to host LT-CMARINS:20000 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
d20002| 2024-05-24T21:59:38.580-0500 I  INITSYNC [replication-0] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1716605977333), totalInitialSyncElapsedMillis: 1246, initialSyncAttempts: [], approxTotalDataSize: 229, approxTotalBytesCopied: 229, remainingInitialSyncEstimatedMillis: 0, fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp(1716605977, 9), initialSyncOplogEnd: Timestamp(1716605977, 9), databases: { databasesToClone: 0, databasesCloned: 2, admin: { collections: 2, clonedCollections: 2, start: new Date(1716605978486), end: new Date(1716605978532), elapsedMillis: 46, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, bytesToCopy: 59, approxBytesCopied: 59, start: new Date(1716605978488), end: new Date(1716605978507), elapsedMillis: 19, receivedBatches: 1 }, admin.system.keys: { documentsToCopy: 2, documentsCopied: 2, indexes: 1, fetchedBatches: 1, bytesToCopy: 170, approxBytesCopied: 170, start: new Date(1716605978507), end: new Date(1716605978532), elapsedMillis: 25, receivedBatches: 1 } }, config: { collections: 2, clonedCollections: 2, start: new Date(1716605978532), end: new Date(1716605978578), elapsedMillis: 46, config.image_collection: { documentsToCopy: 0, documentsCopied: 0, indexes: 1, fetchedBatches: 0, bytesToCopy: 0, start: new Date(1716605978532), end: new Date(1716605978556), elapsedMillis: 24, receivedBatches: 0 }, config.transactions: { documentsToCopy: 0, documentsCopied: 0, indexes: 1, fetchedBatches: 0, bytesToCopy: 0, start: new Date(1716605978556), end: new Date(1716605978578), elapsedMillis: 22, receivedBatches: 0 } } } }
d20002| 2024-05-24T21:59:38.580-0500 I  STORAGE  [replication-1] Finishing collection drop for local.temp_oplog_buffer (fb362e27-2ff1-4c5d-b2b8-14934c2991c7).
d20002| 2024-05-24T21:59:38.582-0500 I  INITSYNC [replication-1] initial sync done; took 1s.
d20002| 2024-05-24T21:59:38.582-0500 I  REPL     [replication-1] transition to RECOVERING from STARTUP2
d20002| 2024-05-24T21:59:38.582-0500 I  REPL     [replication-1] Starting replication fetcher thread
d20002| 2024-05-24T21:59:38.583-0500 I  REPL     [replication-1] Starting replication applier thread
d20002| 2024-05-24T21:59:38.583-0500 I  REPL     [replication-1] Starting replication reporter thread
d20002| 2024-05-24T21:59:38.583-0500 I  REPL     [rsSync-0] Starting oplog application
d20002| 2024-05-24T21:59:38.583-0500 I  REPL     [rsBackgroundSync] could not find member to sync from
d20002| 2024-05-24T21:59:38.584-0500 I  REPL     [rsSync-0] transition to SECONDARY from RECOVERING
d20002| 2024-05-24T21:59:38.584-0500 I  REPL     [rsSync-0] Resetting sync source to empty, which was :27017
d20002| 2024-05-24T21:59:38.584-0500 I  REPL     [replexec-1] Member LT-CMARINS:20001 is now in state SECONDARY
AwaitNodesAgreeOnPrimary: Waiting for nodes to agree on any primary.
AwaitNodesAgreeOnPrimary: Nodes agreed on primary LT-CMARINS:20000
Waiting for keys to sign $clusterTime to be generated
AwaitLastStableRecoveryTimestamp: Beginning for [ "LT-CMARINS:20000", "LT-CMARINS:20001", "LT-CMARINS:20002" ]
AwaitNodesAgreeOnPrimary: Waiting for nodes to agree on any primary.
AwaitNodesAgreeOnPrimary: Nodes agreed on primary LT-CMARINS:20000
AwaitLastStableRecoveryTimestamp: ensuring the commit point advances for [ "LT-CMARINS:20000", "LT-CMARINS:20001", "LT-CMARINS:20002" ]
d20000| 2024-05-24T21:59:38.702-0500 I  NETWORK  [conn14] end connection 192.168.101.72:65109 (5 connections now open)
d20000| 2024-05-24T21:59:38.702-0500 I  NETWORK  [conn10] end connection 192.168.101.72:65105 (6 connections now open)
d20001| 2024-05-24T21:59:39.072-0500 I  REPL     [replexec-4] Member LT-CMARINS:20002 is now in state SECONDARY
d20000| 2024-05-24T21:59:39.261-0500 I  REPL     [replexec-1] Member LT-CMARINS:20001 is now in state SECONDARY
d20000| 2024-05-24T21:59:39.261-0500 I  REPL     [replexec-0] Member LT-CMARINS:20002 is now in state SECONDARY
d20001| 2024-05-24T21:59:39.570-0500 I  REPL     [rsBackgroundSync] sync source candidate: LT-CMARINS:20000
d20001| 2024-05-24T21:59:39.573-0500 I  STORAGE  [replexec-2] Triggering the first stable checkpoint. Initial Data: Timestamp(1716605977, 9) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1716605977, 9)
d20001| 2024-05-24T21:59:39.573-0500 I  REPL     [rsBackgroundSync] Changed sync source from empty to LT-CMARINS:20000
d20001| 2024-05-24T21:59:39.574-0500 I  REPL     [rsBackgroundSync] scheduling fetcher to read remote oplog on LT-CMARINS:20000 starting at filter: { ts: { $gte: Timestamp(1716605977, 9) } }
d20001| 2024-05-24T21:59:39.574-0500 I  CONNPOOL [RS] Connecting to LT-CMARINS:20000
d20000| 2024-05-24T21:59:39.577-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65119 #24 (6 connections now open)
d20000| 2024-05-24T21:59:39.580-0500 I  NETWORK  [conn24] received client metadata from 192.168.101.72:65119 conn24: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T21:59:39.582-0500 I  COMMAND  [conn1] command admin.$cmd appName: "MongoDB Shell" command: appendOplogNote { appendOplogNote: 1.0, data: { awaitLastStableRecoveryTimestamp: 1.0 }, writeConcern: { w: "majority", wtimeout: 600000.0 }, lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716605977, 9), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "admin" } numYields:0 reslen:163 locks:{ ParallelBatchWriterMode: { acquireCount: { r: 1 } }, ReplicationStateTransition: { acquireCount: { w: 1 } }, Global: { acquireCount: { w: 1 } } } flowControl:{ acquireCount: 1, timeAcquiringMicros: 4 } storage:{} protocol:op_msg 881ms
AwaitLastStableRecoveryTimestamp: Waiting for stable recovery timestamps for [ "LT-CMARINS:20000", "LT-CMARINS:20001", "LT-CMARINS:20002" ]
d20002| 2024-05-24T21:59:39.586-0500 I  REPL     [rsBackgroundSync] sync source candidate: LT-CMARINS:20000
AwaitLastStableRecoveryTimestamp: LT-CMARINS:20001 does not have a stable recovery timestamp yet.
d20002| 2024-05-24T21:59:39.587-0500 I  REPL     [rsBackgroundSync] Changed sync source from empty to LT-CMARINS:20000
d20002| 2024-05-24T21:59:39.587-0500 I  STORAGE  [replexec-2] Triggering the first stable checkpoint. Initial Data: Timestamp(1716605977, 9) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1716605977, 9)
d20002| 2024-05-24T21:59:39.588-0500 I  REPL     [rsBackgroundSync] scheduling fetcher to read remote oplog on LT-CMARINS:20000 starting at filter: { ts: { $gte: Timestamp(1716605977, 9) } }
d20002| 2024-05-24T21:59:39.588-0500 I  CONNPOOL [RS] Connecting to LT-CMARINS:20000
d20000| 2024-05-24T21:59:39.591-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65120 #25 (7 connections now open)
d20000| 2024-05-24T21:59:39.593-0500 I  NETWORK  [conn25] received client metadata from 192.168.101.72:65120 conn25: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
AwaitLastStableRecoveryTimestamp: A stable recovery timestamp has successfully established on [ "LT-CMARINS:20000", "LT-CMARINS:20001", "LT-CMARINS:20002" ]


[jsTest] ----
[jsTest] ReplSetTest stepUp: Stepping up LT-CMARINS:20000
[jsTest] ----


ReplSetTest awaitReplication: starting: optime for primary, LT-CMARINS:20000, is { "ts" : Timestamp(1716605979, 1), "t" : NumberLong(1) }
ReplSetTest awaitReplication: checking secondaries against latest primary optime { "ts" : Timestamp(1716605979, 1), "t" : NumberLong(1) }
ReplSetTest awaitReplication: checking secondary #0: LT-CMARINS:20001
ReplSetTest awaitReplication: secondary #0, LT-CMARINS:20001, is synced
ReplSetTest awaitReplication: checking secondary #1: LT-CMARINS:20002
ReplSetTest awaitReplication: secondary #1, LT-CMARINS:20002, is synced
ReplSetTest awaitReplication: finished: all 2 secondaries synced at optime { "ts" : Timestamp(1716605979, 1), "t" : NumberLong(1) }
d20000| 2024-05-24T21:59:39.807-0500 I  COMMAND  [conn1] Received replSetStepUp request
d20000| 2024-05-24T21:59:39.807-0500 I  ELECTION [conn1] Not starting an election for a replSetStepUp request, since we are not electable due to: Not standing for election again; already primary
AwaitNodesAgreeOnPrimary: Waiting for nodes to agree on any primary.
AwaitNodesAgreeOnPrimary: Nodes agreed on primary LT-CMARINS:20000


[jsTest] ----
[jsTest] ReplSetTest stepUp: Finished stepping up LT-CMARINS:20000
[jsTest] ----


> conn=new Mongo("LT-CMARINS:20000")
d20000| 2024-05-24T21:59:44.643-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65121 #26 (8 connections now open)
d20000| 2024-05-24T21:59:44.654-0500 I  NETWORK  [conn26] received client metadata from 192.168.101.72:65121 conn26: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
connection to LT-CMARINS:20000
> testDB=conn.getDB("Diseño_y_operaciones_CRUD")
Diseño_y_operaciones_CRUD
> testDB.isMaster()
{
        "hosts" : [
                "LT-CMARINS:20000",
                "LT-CMARINS:20001",
                "LT-CMARINS:20002"
        ],
        "setName" : "EquipoReplicaSet",
        "setVersion" : 2,
        "ismaster" : true,
        "secondary" : false,
        "primary" : "LT-CMARINS:20000",
        "me" : "LT-CMARINS:20000",
        "electionId" : ObjectId("7fffffff0000000000000001"),
        "lastWrite" : {
                "opTime" : {
                        "ts" : Timestamp(1716605979, 1),
                        "t" : NumberLong(1)
                },
                "lastWriteDate" : ISODate("2024-05-25T02:59:39Z"),
                "majorityOpTime" : {
                        "ts" : Timestamp(1716605979, 1),
                        "t" : NumberLong(1)
                },
                "majorityWriteDate" : ISODate("2024-05-25T02:59:39Z")
        },
        "maxBsonObjectSize" : 16777216,
        "maxMessageSizeBytes" : 48000000,
        "maxWriteBatchSize" : 100000,
        "localTime" : ISODate("2024-05-25T03:00:02.281Z"),
        "logicalSessionTimeoutMinutes" : 30,
        "connectionId" : 26,
        "minWireVersion" : 0,
        "maxWireVersion" : 8,
        "readOnly" : false,
        "ok" : 1,
        "$clusterTime" : {
                "clusterTime" : Timestamp(1716605979, 1),
                "signature" : {
                        "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                        "keyId" : NumberLong(0)
                }
        },
        "operationTime" : Timestamp(1716605979, 1)
}
> testDB.Equipos.insert( { _id:"663effddbed23",Nombre:"Cali",Pais:"Colombia" });
d20000| 2024-05-24T22:00:12.707-0500 I  STORAGE  [conn26] createCollection: Dise├▒o_y_operaciones_CRUD.Equipos with generated UUID: c031e8b3-e0f2-4078-8010-b0293ec162d9 and options: {}
d20000| 2024-05-24T22:00:12.716-0500 I  INDEX    [conn26] index build: done building index _id_ on ns Dise├▒o_y_operaciones_CRUD.Equipos
WriteResult({ "nInserted" : 1 })
> d20001| 2024-05-24T22:00:12.719-0500 I  STORAGE  [repl-writer-worker-1] createCollection: Dise├▒o_y_operaciones_CRUD.Equipos with provided UUID: c031e8b3-e0f2-4078-8010-b0293ec162d9 and options: { uuid: UUID("c031e8b3-e0f2-4078-8010-b0293ec162d9") }
d20002| 2024-05-24T22:00:12.719-0500 I  STORAGE  [repl-writer-worker-1] createCollection: Dise├▒o_y_operaciones_CRUD.Equipos with provided UUID: c031e8b3-e0f2-4078-8010-b0293ec162d9 and options: { uuid: UUID("c031e8b3-e0f2-4078-8010-b0293ec162d9") }
d20002| 2024-05-24T22:00:12.726-0500 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns Dise├▒o_y_operaciones_CRUD.Equipos
d20001| 2024-05-24T22:00:12.727-0500 I  INDEX    [repl-writer-worker-1] index build: done building index _id_ on ns Dise├▒o_y_operaciones_CRUD.Equipos
te
> testDB.Equipos.insert( { _id:"663effddbe33",Nombre:"Once Caldas",Pais:"Colombia" });
WriteResult({ "nInserted" : 1 })
> testDB.Equipos.insert( { _id:"663effddb32",Nombre:"America",Pais:"Colombia" });
WriteResult({ "nInserted" : 1 })
> testDB.Equipos.insert( { _id:"663effddb34",Nombre:"Santa fe",Pais:"Colombia" });
WriteResult({ "nInserted" : 1 })
> testDB.Equipos.insert( { _id:"663effddb54",Nombre:"Nacional",Pais:"Colombia" });
WriteResult({ "nInserted" : 1 })
> testDB.Deportistas.insert( { _id:"363effddb52",Nombre:"Joaquin Papaleo",Rol:"Arquero",Equipo:"663ee2651c" });
d20000| 2024-05-24T22:01:11.113-0500 I  STORAGE  [conn26] createCollection: Dise├▒o_y_operaciones_CRUD.Deportistas with generated UUID: b39b6faa-fab6-48c1-b8ad-89a3186bffb8 and options: {}
d20000| 2024-05-24T22:01:11.120-0500 I  INDEX    [conn26] index build: done building index _id_ on ns Dise├▒o_y_operaciones_CRUD.Deportistas
WriteResult({ "nInserted" : 1 })
> d20002| 2024-05-24T22:01:11.122-0500 I  STORAGE  [repl-writer-worker-2] createCollection: Dise├▒o_y_operaciones_CRUD.Deportistas with provided UUID: b39b6faa-fab6-48c1-b8ad-89a3186bffb8 and options: { uuid: UUID("b39b6faa-fab6-48c1-b8ad-89a3186bffb8") }
d20001| 2024-05-24T22:01:11.122-0500 I  STORAGE  [repl-writer-worker-2] createCollection: Dise├▒o_y_operaciones_CRUD.Deportistas with provided UUID: b39b6faa-fab6-48c1-b8ad-89a3186bffb8 and options: { uuid: UUID("b39b6faa-fab6-48c1-b8ad-89a3186bffb8") }
d20002| 2024-05-24T22:01:11.130-0500 I  INDEX    [repl-writer-worker-2] index build: done building index _id_ on ns Dise├▒o_y_operaciones_CRUD.Deportistas
d20001| 2024-05-24T22:01:11.131-0500 I  INDEX    [repl-writer-worker-2] index build: done building index _id_ on ns Dise├▒o_y_operaciones_CRUD.Deportistas
te
> testDB.Deportistas.insert( { _id:"363effddb53",Nombre:"Carlos Gonzalez",Rol:"CentroCampista",Equipo:"663ee2651c" });
WriteResult({ "nInserted" : 1 })
> testDB.Deportistas.insert( { _id:"363effddb54",Nombre:"Luis Sanchez",Rol:"CentroCampista",Equipo:"663ee2651e" });
WriteResult({ "nInserted" : 1 })
> testDB.Deportistas.insert( { _id:"363effddb55",Nombre:"Jeison Lucumi",Rol:"Delantero",Equipo:"663ee2651e" });
WriteResult({ "nInserted" : 1 })
> connSecondary=new Mongo("LT-CMARINS:20001")
d20001| 2024-05-24T22:01:49.851-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65139 #18 (4 connections now open)
d20001| 2024-05-24T22:01:49.860-0500 I  NETWORK  [conn18] received client metadata from 192.168.101.72:65139 conn18: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
connection to LT-CMARINS:20001
> secondaryTestDB=connSecondary.getDB("Diseño_y_operaciones_CRUD")
Diseño_y_operaciones_CRUD
> secondaryTestDB.isMaster()
{
        "hosts" : [
                "LT-CMARINS:20000",
                "LT-CMARINS:20001",
                "LT-CMARINS:20002"
        ],
        "setName" : "EquipoReplicaSet",
        "setVersion" : 2,
        "ismaster" : false,
        "secondary" : true,
        "primary" : "LT-CMARINS:20000",
        "me" : "LT-CMARINS:20001",
        "lastWrite" : {
                "opTime" : {
                        "ts" : Timestamp(1716606101, 1),
                        "t" : NumberLong(1)
                },
                "lastWriteDate" : ISODate("2024-05-25T03:01:41Z"),
                "majorityOpTime" : {
                        "ts" : Timestamp(1716606101, 1),
                        "t" : NumberLong(1)
                },
                "majorityWriteDate" : ISODate("2024-05-25T03:01:41Z")
        },
        "maxBsonObjectSize" : 16777216,
        "maxMessageSizeBytes" : 48000000,
        "maxWriteBatchSize" : 100000,
        "localTime" : ISODate("2024-05-25T03:02:00.118Z"),
        "logicalSessionTimeoutMinutes" : 30,
        "connectionId" : 18,
        "minWireVersion" : 0,
        "maxWireVersion" : 8,
        "readOnly" : false,
        "ok" : 1,
        "$clusterTime" : {
                "clusterTime" : Timestamp(1716606101, 1),
                "signature" : {
                        "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                        "keyId" : NumberLong(0)
                }
        },
        "operationTime" : Timestamp(1716606101, 1)
}
> secondaryTestDB.Deportistas.count()
2024-05-24T22:02:09.276-0500 E  QUERY    [js] uncaught exception: Error: count failed: {
        "operationTime" : Timestamp(1716606101, 1),
        "ok" : 0,
        "errmsg" : "not master and slaveOk=false",
        "code" : 13435,
        "codeName" : "NotPrimaryNoSecondaryOk",
        "$clusterTime" : {
                "clusterTime" : Timestamp(1716606101, 1),
                "signature" : {
                        "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                        "keyId" : NumberLong(0)
                }
        }
} :
_getErrorWithCode@src/mongo/shell/utils.js:25:13
DBQuery.prototype.count@src/mongo/shell/query.js:376:11
DBCollection.prototype.count@src/mongo/shell/collection.js:1401:12
@(shell):1:1
> connSecondary.setSecondaryOk()
> secondaryTestDB.Deportistas.count()
4
> secondaryTestDB.Deportistas.find().pretty()
{
        "_id" : "363effddb52",
        "Nombre" : "Joaquin Papaleo",
        "Rol" : "Arquero",
        "Equipo" : "663ee2651c"
}
{
        "_id" : "363effddb53",
        "Nombre" : "Carlos Gonzalez",
        "Rol" : "CentroCampista",
        "Equipo" : "663ee2651c"
}
{
        "_id" : "363effddb54",
        "Nombre" : "Luis Sanchez",
        "Rol" : "CentroCampista",
        "Equipo" : "663ee2651e"
}
{
        "_id" : "363effddb55",
        "Nombre" : "Jeison Lucumi",
        "Rol" : "Delantero",
        "Equipo" : "663ee2651e"
}
> connSecondary = new Mongo("LT-CMARINS:20002")
d20002| 2024-05-24T22:02:35.098-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65148 #18 (4 connections now open)
d20002| 2024-05-24T22:02:35.099-0500 I  NETWORK  [conn18] received client metadata from 192.168.101.72:65148 conn18: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
connection to LT-CMARINS:20002
> secondaryTestDB=connSecondary.getDB("Diseño_y_operaciones_CRUD")
Diseño_y_operaciones_CRUD
> secondaryTestDB.isMaster()
{
        "hosts" : [
                "LT-CMARINS:20000",
                "LT-CMARINS:20001",
                "LT-CMARINS:20002"
        ],
        "setName" : "EquipoReplicaSet",
        "setVersion" : 2,
        "ismaster" : false,
        "secondary" : true,
        "primary" : "LT-CMARINS:20000",
        "me" : "LT-CMARINS:20002",
        "lastWrite" : {
                "opTime" : {
                        "ts" : Timestamp(1716606101, 1),
                        "t" : NumberLong(1)
                },
                "lastWriteDate" : ISODate("2024-05-25T03:01:41Z"),
                "majorityOpTime" : {
                        "ts" : Timestamp(1716606101, 1),
                        "t" : NumberLong(1)
                },
                "majorityWriteDate" : ISODate("2024-05-25T03:01:41Z")
        },
        "maxBsonObjectSize" : 16777216,
        "maxMessageSizeBytes" : 48000000,
        "maxWriteBatchSize" : 100000,
        "localTime" : ISODate("2024-05-25T03:02:46.186Z"),
        "logicalSessionTimeoutMinutes" : 30,
        "connectionId" : 18,
        "minWireVersion" : 0,
        "maxWireVersion" : 8,
        "readOnly" : false,
        "ok" : 1,
        "$clusterTime" : {
                "clusterTime" : Timestamp(1716606101, 1),
                "signature" : {
                        "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                        "keyId" : NumberLong(0)
                }
        },
        "operationTime" : Timestamp(1716606101, 1)
}
> connSecondary.setSecondaryOk()
> connPrimary=new Mongo( "LT-CMARINS:20002")
d20002| 2024-05-24T22:02:57.947-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65155 #19 (5 connections now open)
d20002| 2024-05-24T22:02:57.957-0500 I  NETWORK  [conn19] received client metadata from 192.168.101.72:65155 conn19: { application: { name: "MongoDB Shell" }, driver: { name: "MongoDB Internal Client", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
connection to LT-CMARINS:20002
> primaryDB = connPrimary.getDB("Diseño_y_operaciones_CRUD")
Diseño_y_operaciones_CRUD
> primaryDB.isMaster()
{
        "hosts" : [
                "LT-CMARINS:20000",
                "LT-CMARINS:20001",
                "LT-CMARINS:20002"
        ],
        "setName" : "EquipoReplicaSet",
        "setVersion" : 2,
        "ismaster" : false,
        "secondary" : true,
        "primary" : "LT-CMARINS:20000",
        "me" : "LT-CMARINS:20002",
        "lastWrite" : {
                "opTime" : {
                        "ts" : Timestamp(1716606101, 1),
                        "t" : NumberLong(1)
                },
                "lastWriteDate" : ISODate("2024-05-25T03:01:41Z"),
                "majorityOpTime" : {
                        "ts" : Timestamp(1716606101, 1),
                        "t" : NumberLong(1)
                },
                "majorityWriteDate" : ISODate("2024-05-25T03:01:41Z")
        },
        "maxBsonObjectSize" : 16777216,
        "maxMessageSizeBytes" : 48000000,
        "maxWriteBatchSize" : 100000,
        "localTime" : ISODate("2024-05-25T03:03:07.613Z"),
        "logicalSessionTimeoutMinutes" : 30,
        "connectionId" : 19,
        "minWireVersion" : 0,
        "maxWireVersion" : 8,
        "readOnly" : false,
        "ok" : 1,
        "$clusterTime" : {
                "clusterTime" : Timestamp(1716606101, 1),
                "signature" : {
                        "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),
                        "keyId" : NumberLong(0)
                }
        },
        "operationTime" : Timestamp(1716606101, 1)
}
> EquipoReplicaSet.stopSet()
ReplSetTest stopSet going to run data consistency checks.
ReplSetTest stopSet checking oplogs.
d20000| 2024-05-24T22:03:15.166-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "Deportistas", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606101, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "Dise├▒o_y_operaciones_CRUD" }
d20000| 2024-05-24T22:03:15.167-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "Equipos", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606195, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "Dise├▒o_y_operaciones_CRUD" }
d20000| 2024-05-24T22:03:15.169-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "image_collection", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606195, 2), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "config" }
d20000| 2024-05-24T22:03:15.169-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "transactions", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606195, 3), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "config" }
d20000| 2024-05-24T22:03:15.170-0500 I  COMMAND  [conn1] CMD fsync: sync:1 lock:1
d20002| 2024-05-24T22:03:15.171-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Deportistas" }
d20001| 2024-05-24T22:03:15.171-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Deportistas" }
d20002| 2024-05-24T22:03:15.173-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Equipos" }
d20001| 2024-05-24T22:03:15.174-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Equipos" }
d20001| 2024-05-24T22:03:15.181-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "image_collection" }
d20002| 2024-05-24T22:03:15.181-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "image_collection" }
d20002| 2024-05-24T22:03:15.182-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "transactions" }
d20001| 2024-05-24T22:03:15.182-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "transactions" }
d20000| 2024-05-24T22:03:15.196-0500 W  COMMAND  [fsyncLockWorker] WARNING: instance is locked, blocking all writes. The fsync command has finished execution, remember to unlock the instance using fsyncUnlock().
d20000| 2024-05-24T22:03:15.196-0500 I  COMMAND  [conn1] mongod is locked and no writes are allowed. db.fsyncUnlock() to unlock
d20000| 2024-05-24T22:03:15.196-0500 I  COMMAND  [conn1] Lock count is 1
ReplSetTest awaitReplication: going to check only LT-CMARINS:20001,LT-CMARINS:20002
d20000| 2024-05-24T22:03:15.196-0500 I  COMMAND  [conn1]     For more info see http://dochub.mongodb.org/core/fsynccommand
ReplSetTest awaitReplication: starting: optime for primary, LT-CMARINS:20000, is { "ts" : Timestamp(1716606195, 4), "t" : NumberLong(1) }
ReplSetTest awaitReplication: checking secondaries against latest primary optime { "ts" : Timestamp(1716606195, 4), "t" : NumberLong(1) }
ReplSetTest awaitReplication: checking secondary #0: LT-CMARINS:20001
ReplSetTest awaitReplication: secondary #0, LT-CMARINS:20001, is synced
ReplSetTest awaitReplication: checking secondary #1: LT-CMARINS:20002
ReplSetTest awaitReplication: secondary #1, LT-CMARINS:20002, is synced
ReplSetTest awaitReplication: finished: all 2 secondaries synced at optime { "ts" : Timestamp(1716606195, 4), "t" : NumberLong(1) }
checkOplogs starting oplog checks.
checkOplogs going to check oplog of node: LT-CMARINS:20000
checkOplogs going to check oplog of node: LT-CMARINS:20001
checkOplogs going to check oplog of node: LT-CMARINS:20002
checkOplogs oplog checks complete.
d20000| 2024-05-24T22:03:15.234-0500 I  COMMAND  [conn1] command: unlock requested
d20000| 2024-05-24T22:03:15.235-0500 I  COMMAND  [conn1] fsyncUnlock completed. mongod is now unlocked and free to accept writes
ReplSetTest stopSet checking replicated data hashes.
d20000| 2024-05-24T22:03:15.244-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "Deportistas", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606195, 4), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "Dise├▒o_y_operaciones_CRUD" }
d20000| 2024-05-24T22:03:15.244-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "Equipos", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606195, 5), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "Dise├▒o_y_operaciones_CRUD" }
d20000| 2024-05-24T22:03:15.246-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "image_collection", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606195, 6), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "config" }
d20001| 2024-05-24T22:03:15.248-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Deportistas" }
d20002| 2024-05-24T22:03:15.248-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Deportistas" }
d20000| 2024-05-24T22:03:15.247-0500 I  COMMAND  [conn1] CMD: collMod: { collMod: "transactions", lsid: { id: UUID("a1a72bac-fc9c-47b7-a267-3c3704dc648d") }, $clusterTime: { clusterTime: Timestamp(1716606195, 7), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $readPreference: { mode: "secondaryPreferred" }, $db: "config" }
d20002| 2024-05-24T22:03:15.250-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Equipos" }
d20001| 2024-05-24T22:03:15.250-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "Equipos" }
d20000| 2024-05-24T22:03:15.247-0500 I  COMMAND  [conn1] CMD fsync: sync:1 lock:1
d20001| 2024-05-24T22:03:15.261-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "image_collection" }
d20002| 2024-05-24T22:03:15.261-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "image_collection" }
d20002| 2024-05-24T22:03:15.262-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "transactions" }
d20001| 2024-05-24T22:03:15.262-0500 I  COMMAND  [repl-writer-worker-3] CMD: collMod: { collMod: "transactions" }
d20000| 2024-05-24T22:03:15.274-0500 W  COMMAND  [fsyncLockWorker] WARNING: instance is locked, blocking all writes. The fsync command has finished execution, remember to unlock the instance using fsyncUnlock().
ReplSetTest awaitReplication: going to check only LT-CMARINS:20001,LT-CMARINS:20002
d20000| 2024-05-24T22:03:15.274-0500 I  COMMAND  [conn1] mongod is locked and no writes are allowed. db.fsyncUnlock() to unlock
d20000| 2024-05-24T22:03:15.274-0500 I  COMMAND  [conn1] Lock count is 1
d20000| 2024-05-24T22:03:15.274-0500 I  COMMAND  [conn1]     For more info see http://dochub.mongodb.org/core/fsynccommand
ReplSetTest awaitReplication: starting: optime for primary, LT-CMARINS:20000, is { "ts" : Timestamp(1716606195, 8), "t" : NumberLong(1) }
ReplSetTest awaitReplication: checking secondaries against latest primary optime { "ts" : Timestamp(1716606195, 8), "t" : NumberLong(1) }
ReplSetTest awaitReplication: checking secondary #0: LT-CMARINS:20001
ReplSetTest awaitReplication: secondary #0, LT-CMARINS:20001, is synced
ReplSetTest awaitReplication: checking secondary #1: LT-CMARINS:20002
ReplSetTest awaitReplication: secondary #1, LT-CMARINS:20002, is synced
ReplSetTest awaitReplication: finished: all 2 secondaries synced at optime { "ts" : Timestamp(1716606195, 8), "t" : NumberLong(1) }
checkDBHashesForReplSet checking data hashes against primary: LT-CMARINS:20000
checkDBHashesForReplSet going to check data hashes on secondary: LT-CMARINS:20001
checkDBHashesForReplSet going to check data hashes on secondary: LT-CMARINS:20002
d20001| 2024-05-24T22:03:15.326-0500 I  NETWORK  [conn18] end connection 192.168.101.72:65139 (3 connections now open)
d20000| 2024-05-24T22:03:15.379-0500 I  COMMAND  [conn1] command: unlock requested
d20000| 2024-05-24T22:03:15.380-0500 I  COMMAND  [conn1] fsyncUnlock completed. mongod is now unlocked and free to accept writes
ReplSetTest stopSet finished data consistency checks.
ReplSetTest stopSet disabling 'waitForStepDownOnNonCommandShutdown' on LT-CMARINS:20000
d20000| 2024-05-24T22:03:15.386-0500 I  COMMAND  [conn1] successfully set parameter waitForStepDownOnNonCommandShutdown to false (was true)
ReplSetTest stopSet disabling 'waitForStepDownOnNonCommandShutdown' on LT-CMARINS:20001
d20001| 2024-05-24T22:03:15.386-0500 I  COMMAND  [conn1] successfully set parameter waitForStepDownOnNonCommandShutdown to false (was true)
ReplSetTest stopSet disabling 'waitForStepDownOnNonCommandShutdown' on LT-CMARINS:20002
d20002| 2024-05-24T22:03:15.387-0500 I  COMMAND  [conn1] successfully set parameter waitForStepDownOnNonCommandShutdown to false (was true)
ReplSetTest stopSet stopping all replica set nodes.
ReplSetTest stop *** Shutting down mongod in port 20000 ***
d20000| 2024-05-24T22:03:15.388-0500 I  CONTROL  [eventTerminate] shutdown event signaled, will terminate after current cmd ends
d20000| 2024-05-24T22:03:15.388-0500 I  REPL     [eventTerminate] Stepping down the ReplicationCoordinator for shutdown, waitTime: 100ms
d20000| 2024-05-24T22:03:15.388-0500 I  REPL     [RstlKillOpThread] Starting to kill user operations
d20000| 2024-05-24T22:03:15.388-0500 I  REPL     [RstlKillOpThread] Stopped killing user operations
d20000| 2024-05-24T22:03:15.388-0500 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 2 }
d20001| 2024-05-24T22:03:15.389-0500 I  COMMAND  [conn3] Received replSetStepUp request
d20000| 2024-05-24T22:03:15.389-0500 I  REPL     [eventTerminate] transition to SECONDARY from PRIMARY
d20001| 2024-05-24T22:03:15.389-0500 I  ELECTION [conn3] Starting an election due to step up request
d20001| 2024-05-24T22:03:15.389-0500 I  ELECTION [conn3] skipping dry run and running for election in term 2
d20000| 2024-05-24T22:03:15.389-0500 I  REPL     [eventTerminate] Handing off election to LT-CMARINS:20001
d20000| 2024-05-24T22:03:15.389-0500 I  SHARDING [eventTerminate] Shutting down the WaitForMajorityService
d20000| 2024-05-24T22:03:15.391-0500 I  CONTROL  [eventTerminate] Shutting down the LogicalSessionCache
d20000| 2024-05-24T22:03:15.391-0500 I  NETWORK  [eventTerminate] shutdown: going to close listening sockets...
d20001| 2024-05-24T22:03:15.391-0500 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 407 -- target:LT-CMARINS:20000 db:admin cmd:{ replSetRequestVotes: 1, setName: "EquipoReplicaSet", dryRun: false, term: 2, candidateIndex: 1, configVersion: 2, lastCommittedOp: { ts: Timestamp(1716606195, 8), t: 1 } }
d20001| 2024-05-24T22:03:15.391-0500 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 408 -- target:LT-CMARINS:20002 db:admin cmd:{ replSetRequestVotes: 1, setName: "EquipoReplicaSet", dryRun: false, term: 2, candidateIndex: 1, configVersion: 2, lastCommittedOp: { ts: Timestamp(1716606195, 8), t: 1 } }
d20000| 2024-05-24T22:03:15.392-0500 I  NETWORK  [eventTerminate] Shutting down the global connection pool
d20000| 2024-05-24T22:03:15.392-0500 I  STORAGE  [eventTerminate] Shutting down the FlowControlTicketholder
d20000| 2024-05-24T22:03:15.392-0500 I  -        [eventTerminate] Stopping further Flow Control ticket acquisitions.
d20000| 2024-05-24T22:03:15.392-0500 I  STORAGE  [eventTerminate] Shutting down the PeriodicThreadToAbortExpiredTransactions
d20000| 2024-05-24T22:03:15.392-0500 I  STORAGE  [eventTerminate] Shutting down the PeriodicThreadToDecreaseSnapshotHistoryIfNotNeeded
d20000| 2024-05-24T22:03:15.392-0500 I  REPL     [eventTerminate] Shutting down the ReplicationCoordinator
d20000| 2024-05-24T22:03:15.392-0500 I  REPL     [eventTerminate] shutting down replication subsystems
d20000| 2024-05-24T22:03:15.393-0500 I  REPL     [eventTerminate] Stopping replication reporter thread
d20000| 2024-05-24T22:03:15.393-0500 I  REPL     [eventTerminate] Stopping replication fetcher thread
d20000| 2024-05-24T22:03:15.393-0500 I  REPL     [eventTerminate] Stopping replication applier thread
d20001| 2024-05-24T22:03:15.393-0500 I  ELECTION [replexec-6] VoteRequester(term 2) received an invalid response from LT-CMARINS:20000: ShutdownInProgress: In the process of shutting down; response message: { operationTime: Timestamp(1716606195, 8), ok: 0.0, errmsg: "In the process of shutting down", code: 91, codeName: "ShutdownInProgress", $clusterTime: { clusterTime: Timestamp(1716606195, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } } }
d20001| 2024-05-24T22:03:15.393-0500 I  ELECTION [replexec-5] VoteRequester(term 2) received a yes vote from LT-CMARINS:20002; response message: { term: 2, voteGranted: true, reason: "", ok: 1.0, $clusterTime: { clusterTime: Timestamp(1716606195, 8), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, operationTime: Timestamp(1716606195, 8) }
d20001| 2024-05-24T22:03:15.393-0500 I  ELECTION [replexec-2] election succeeded, assuming primary role in term 2
d20001| 2024-05-24T22:03:15.393-0500 I  REPL     [replexec-2] transition to PRIMARY from SECONDARY
d20001| 2024-05-24T22:03:15.393-0500 I  REPL     [replexec-2] Resetting sync source to empty, which was LT-CMARINS:20000
d20001| 2024-05-24T22:03:15.395-0500 I  REPL     [replexec-2] Entering primary catch-up mode.
d20001| 2024-05-24T22:03:15.395-0500 I  REPL     [replexec-2] Member LT-CMARINS:20000 is now in state SECONDARY
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [replexec-5] Caught up to the latest optime known via heartbeats after becoming primary. Target optime: { ts: Timestamp(1716606195, 8), t: 1 }. My Last Applied: { ts: Timestamp(1716606195, 8), t: 1 }
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [replexec-5] Exited primary catch-up mode.
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [replexec-5] Stopping replication producer
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [rsBackgroundSync] Replication producer stopped after oplog fetcher finished returning a batch from our sync source.  Abandoning this batch of oplog entries and re-evaluating our sync source.
d20001| 2024-05-24T22:03:15.396-0500 I  CONNPOOL [RS] Ending connection to host LT-CMARINS:20000 due to bad connection status: CallbackCanceled: Callback was canceled; 1 connections to that host remain open
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [ReplBatcher] Oplog buffer has been drained in term 2
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [RstlKillOpThread] Starting to kill user operations
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [RstlKillOpThread] Stopped killing user operations
d20001| 2024-05-24T22:03:15.396-0500 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepUp", userOpsKilled: 0, userOpsRunning: 0 }
d20001| 2024-05-24T22:03:15.397-0500 I  REPL     [rsSync-0] transition to primary complete; database writes are now permitted
d20002| 2024-05-24T22:03:15.392-0500 I  ELECTION [conn9] Received vote request: { replSetRequestVotes: 1, setName: "EquipoReplicaSet", dryRun: false, term: 2, candidateIndex: 1, configVersion: 2, lastCommittedOp: { ts: Timestamp(1716606195, 8), t: 1 } }
d20002| 2024-05-24T22:03:15.392-0500 I  ELECTION [conn9] Sending vote response: { term: 2, voteGranted: true, reason: "" }
d20002| 2024-05-24T22:03:15.674-0500 I  REPL     [replexec-0] Member LT-CMARINS:20000 is now in state SECONDARY
d20002| 2024-05-24T22:03:15.674-0500 I  REPL     [replexec-2] Member LT-CMARINS:20001 is now in state PRIMARY
d20000| 2024-05-24T22:03:16.292-0500 I  REPL     [rsSync-0] Finished oplog application
d20000| 2024-05-24T22:03:16.390-0500 I  REPL     [rsBackgroundSync] Stopping replication producer
d20000| 2024-05-24T22:03:16.390-0500 I  REPL     [eventTerminate] Stopping replication storage threads
d20000| 2024-05-24T22:03:16.391-0500 I  ASIO     [RS] Killing all outstanding egress activity.
d20000| 2024-05-24T22:03:16.391-0500 I  ASIO     [RS] Killing all outstanding egress activity.
d20000| 2024-05-24T22:03:16.393-0500 I  ASIO     [Replication] Killing all outstanding egress activity.
d20000| 2024-05-24T22:03:16.394-0500 I  CONNPOOL [Replication] Dropping all pooled connections to LT-CMARINS:20002 due to ShutdownInProgress: Shutting down the connection pool
d20000| 2024-05-24T22:03:16.394-0500 I  CONNPOOL [Replication] Dropping all pooled connections to LT-CMARINS:20001 due to ShutdownInProgress: Shutting down the connection pool
d20002| 2024-05-24T22:03:16.395-0500 I  NETWORK  [conn3] end connection 192.168.101.72:65096 (4 connections now open)
d20001| 2024-05-24T22:03:16.395-0500 I  NETWORK  [conn3] end connection 192.168.101.72:65095 (2 connections now open)
d20000| 2024-05-24T22:03:16.395-0500 I  SHARDING [eventTerminate] Shutting down the ShardingInitializationMongoD
d20000| 2024-05-24T22:03:16.395-0500 I  REPL     [eventTerminate] Enqueuing the ReplicationStateTransitionLock for shutdown
d20000| 2024-05-24T22:03:16.395-0500 I  -        [eventTerminate] Killing all operations for shutdown
d20000| 2024-05-24T22:03:16.395-0500 I  COMMAND  [eventTerminate] Shutting down all open transactions
d20000| 2024-05-24T22:03:16.395-0500 I  REPL     [eventTerminate] Acquiring the ReplicationStateTransitionLock for shutdown
d20000| 2024-05-24T22:03:16.395-0500 I  INDEX    [eventTerminate] Shutting down the IndexBuildsCoordinator
d20000| 2024-05-24T22:03:16.395-0500 I  NETWORK  [eventTerminate] Shutting down the ReplicaSetMonitor
d20000| 2024-05-24T22:03:16.396-0500 I  REPL     [eventTerminate] Shutting down the LogicalTimeValidator
d20000| 2024-05-24T22:03:16.397-0500 I  CONTROL  [eventTerminate] Shutting down free monitoring
d20000| 2024-05-24T22:03:16.397-0500 I  CONTROL  [eventTerminate] Shutting down free monitoring
d20000| 2024-05-24T22:03:16.397-0500 I  FTDC     [eventTerminate] Shutting down full-time data capture
d20000| 2024-05-24T22:03:16.397-0500 I  FTDC     [eventTerminate] Shutting down full-time diagnostic data capture
d20000| 2024-05-24T22:03:16.399-0500 I  STORAGE  [eventTerminate] Shutting down the HealthLog
d20000| 2024-05-24T22:03:16.399-0500 I  STORAGE  [eventTerminate] Shutting down the storage engine
d20000| 2024-05-24T22:03:16.399-0500 I  STORAGE  [eventTerminate] Deregistering all the collections
d20000| 2024-05-24T22:03:16.399-0500 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
d20000| 2024-05-24T22:03:16.399-0500 I  STORAGE  [eventTerminate] Timestamp monitor shutting down
d20000| 2024-05-24T22:03:16.400-0500 I  STORAGE  [eventTerminate] WiredTigerKVEngine shutting down
d20000| 2024-05-24T22:03:16.400-0500 I  STORAGE  [eventTerminate] Shutting down session sweeper thread
d20000| 2024-05-24T22:03:16.400-0500 I  STORAGE  [eventTerminate] Finished shutting down session sweeper thread
d20000| 2024-05-24T22:03:16.400-0500 I  STORAGE  [eventTerminate] Shutting down journal flusher thread
d20000| 2024-05-24T22:03:16.402-0500 W  QUERY    [conn24] GetMore command executor error: FAILURE, status: InterruptedAtShutdown: interrupted at shutdown, stats: { stage: "COLLSCAN", nReturned: 22, executionTimeMillisEstimate: 2, works: 472, advanced: 22, needTime: 225, needYield: 0, saveState: 225, restoreState: 224, isEOF: 0, direction: "forward", docsExamined: 22 }
d20000| 2024-05-24T22:03:16.402-0500 W  QUERY    [conn25] GetMore command executor error: FAILURE, status: InterruptedAtShutdown: interrupted at shutdown, stats: { stage: "COLLSCAN", nReturned: 22, executionTimeMillisEstimate: 2, works: 454, advanced: 22, needTime: 216, needYield: 0, saveState: 216, restoreState: 215, isEOF: 0, direction: "forward", docsExamined: 22 }
d20000| 2024-05-24T22:03:16.403-0500 I  NETWORK  [conn24] end connection 192.168.101.72:65119 (7 connections now open)
d20002| 2024-05-24T22:03:16.403-0500 I  REPL     [replication-2] Restarting oplog query due to error: InterruptedAtShutdown: error in fetcher batch callback :: caused by :: interrupted at shutdown. Last fetched optime: { ts: Timestamp(1716606195, 8), t: 1 }. Restarts remaining: 1
d20002| 2024-05-24T22:03:16.403-0500 I  REPL     [replication-2] Scheduled new oplog query Fetcher source: LT-CMARINS:20000 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1716606195, 8) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 2, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 10000ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 404 -- target:LT-CMARINS:20000 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1716606195, 8) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 2, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
d20002| 2024-05-24T22:03:16.403-0500 I  REPL     [replication-3] Error returned from oplog query (no more query restarts left): InterruptedAtShutdown: error in fetcher batch callback :: caused by :: interrupted at shutdown
d20002| 2024-05-24T22:03:16.403-0500 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InterruptedAtShutdown: error in fetcher batch callback :: caused by :: interrupted at shutdown
d20002| 2024-05-24T22:03:16.404-0500 I  REPL     [rsBackgroundSync] Clearing sync source LT-CMARINS:20000 to choose a new one.
d20002| 2024-05-24T22:03:16.404-0500 I  REPL     [rsBackgroundSync] sync source candidate: LT-CMARINS:20001
d20002| 2024-05-24T22:03:16.404-0500 I  CONNPOOL [RS] Connecting to LT-CMARINS:20001
d20001| 2024-05-24T22:03:16.405-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65158 #19 (3 connections now open)
d20002| 2024-05-24T22:03:16.407-0500 I  REPL     [rsBackgroundSync] Changed sync source from LT-CMARINS:20000 to LT-CMARINS:20001
d20001| 2024-05-24T22:03:16.406-0500 I  NETWORK  [conn19] received client metadata from 192.168.101.72:65158 conn19: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20002| 2024-05-24T22:03:16.407-0500 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to LT-CMARINS:20000: InvalidSyncSource: Sync source changed from LT-CMARINS:20000 to LT-CMARINS:20001
d20002| 2024-05-24T22:03:16.407-0500 I  REPL     [rsBackgroundSync] scheduling fetcher to read remote oplog on LT-CMARINS:20001 starting at filter: { ts: { $gte: Timestamp(1716606195, 8) } }
d20001| 2024-05-24T22:03:16.408-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65159 #20 (4 connections now open)
d20001| 2024-05-24T22:03:16.408-0500 I  NETWORK  [conn20] received client metadata from 192.168.101.72:65159 conn20: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20000| 2024-05-24T22:03:16.420-0500 I  STORAGE  [eventTerminate] Finished shutting down journal flusher thread
d20000| 2024-05-24T22:03:16.420-0500 I  STORAGE  [eventTerminate] Shutting down checkpoint thread
d20000| 2024-05-24T22:03:16.420-0500 I  STORAGE  [eventTerminate] Finished shutting down checkpoint thread
d20000| 2024-05-24T22:03:16.434-0500 I  STORAGE  [eventTerminate] shutdown: removing fs lock...
d20000| 2024-05-24T22:03:16.434-0500 I  -        [eventTerminate] Dropping the scope cache for shutdown
d20000| 2024-05-24T22:03:16.434-0500 I  CONTROL  [eventTerminate] now exiting
d20000| 2024-05-24T22:03:16.435-0500 I  CONTROL  [eventTerminate] shutting down with code:0
2024-05-24T22:03:16.469-0500 I  -        [js] shell: stopped mongo program on port 20000
ReplSetTest stop *** Mongod in port 20000 shutdown with code (0) ***
ReplSetTest stop *** Shutting down mongod in port 20001 ***
d20001| 2024-05-24T22:03:16.478-0500 I  CONTROL  [eventTerminate] shutdown event signaled, will terminate after current cmd ends
d20001| 2024-05-24T22:03:16.478-0500 I  REPL     [eventTerminate] Stepping down the ReplicationCoordinator for shutdown, waitTime: 100ms
d20001| 2024-05-24T22:03:16.479-0500 I  REPL     [RstlKillOpThread] Starting to kill user operations
d20001| 2024-05-24T22:03:16.479-0500 I  REPL     [RstlKillOpThread] Stopped killing user operations
d20001| 2024-05-24T22:03:16.479-0500 I  REPL     [RstlKillOpThread] State transition ops metrics: { lastStateTransition: "stepDown", userOpsKilled: 0, userOpsRunning: 1 }
d20001| 2024-05-24T22:03:16.479-0500 I  REPL     [eventTerminate] transition to SECONDARY from PRIMARY
d20001| 2024-05-24T22:03:16.479-0500 I  REPL     [eventTerminate] Handing off election to LT-CMARINS:20002
d20001| 2024-05-24T22:03:16.479-0500 I  SHARDING [eventTerminate] Shutting down the WaitForMajorityService
d20001| 2024-05-24T22:03:16.480-0500 I  CONTROL  [eventTerminate] Shutting down the LogicalSessionCache
d20001| 2024-05-24T22:03:16.480-0500 I  NETWORK  [eventTerminate] shutdown: going to close listening sockets...
d20001| 2024-05-24T22:03:16.480-0500 I  NETWORK  [eventTerminate] Shutting down the global connection pool
d20001| 2024-05-24T22:03:16.480-0500 I  STORAGE  [eventTerminate] Shutting down the FlowControlTicketholder
d20001| 2024-05-24T22:03:16.480-0500 I  -        [eventTerminate] Stopping further Flow Control ticket acquisitions.
d20001| 2024-05-24T22:03:16.480-0500 I  STORAGE  [eventTerminate] Shutting down the PeriodicThreadToAbortExpiredTransactions
d20001| 2024-05-24T22:03:16.480-0500 I  STORAGE  [eventTerminate] Shutting down the PeriodicThreadToDecreaseSnapshotHistoryIfNotNeeded
d20001| 2024-05-24T22:03:16.480-0500 I  REPL     [eventTerminate] Shutting down the ReplicationCoordinator
d20001| 2024-05-24T22:03:16.480-0500 I  REPL     [eventTerminate] shutting down replication subsystems
d20001| 2024-05-24T22:03:16.480-0500 I  REPL     [eventTerminate] Stopping replication reporter thread
d20001| 2024-05-24T22:03:16.480-0500 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to LT-CMARINS:20000: CallbackCanceled: Reporter no longer valid
d20002| 2024-05-24T22:03:16.480-0500 I  COMMAND  [conn9] Received replSetStepUp request
d20001| 2024-05-24T22:03:16.480-0500 I  REPL     [eventTerminate] Stopping replication fetcher thread
d20002| 2024-05-24T22:03:16.480-0500 I  ELECTION [conn9] Starting an election due to step up request
d20002| 2024-05-24T22:03:16.480-0500 I  ELECTION [conn9] skipping dry run and running for election in term 3
d20002| 2024-05-24T22:03:16.481-0500 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 413 -- target:LT-CMARINS:20000 db:admin cmd:{ replSetRequestVotes: 1, setName: "EquipoReplicaSet", dryRun: false, term: 3, candidateIndex: 2, configVersion: 2, lastCommittedOp: { ts: Timestamp(1716606195, 10), t: 2 } }
d20002| 2024-05-24T22:03:16.481-0500 W  NETWORK  [replexec-2] Failed to check socket connectivity: La operaci├│n se complet├│ correctamente.
d20002| 2024-05-24T22:03:16.481-0500 I  CONNPOOL [replexec-2] dropping unhealthy pooled connection to LT-CMARINS:20000
d20002| 2024-05-24T22:03:16.481-0500 I  REPL     [replexec-2] Scheduling remote command request for vote request: RemoteCommand 414 -- target:LT-CMARINS:20001 db:admin cmd:{ replSetRequestVotes: 1, setName: "EquipoReplicaSet", dryRun: false, term: 3, candidateIndex: 2, configVersion: 2, lastCommittedOp: { ts: Timestamp(1716606195, 10), t: 2 } }
d20002| 2024-05-24T22:03:16.481-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20000
d20001| 2024-05-24T22:03:16.480-0500 I  REPL     [eventTerminate] Stopping replication applier thread
d20002| 2024-05-24T22:03:16.482-0500 I  ELECTION [replexec-0] VoteRequester(term 3) received an invalid response from LT-CMARINS:20001: ShutdownInProgress: In the process of shutting down; response message: { operationTime: Timestamp(1716606195, 10), ok: 0.0, errmsg: "In the process of shutting down", code: 91, codeName: "ShutdownInProgress", $clusterTime: { clusterTime: Timestamp(1716606195, 10), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } } }
d20001| 2024-05-24T22:03:17.395-0500 W  NETWORK  [replexec-7] Failed to check socket connectivity: La operaci├│n se complet├│ correctamente.
d20001| 2024-05-24T22:03:17.396-0500 I  CONNPOOL [replexec-7] dropping unhealthy pooled connection to LT-CMARINS:20000
d20001| 2024-05-24T22:03:17.396-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20000
d20002| 2024-05-24T22:03:17.397-0500 I  NETWORK  [listener] connection accepted from 192.168.101.72:65162 #22 (5 connections now open)
d20002| 2024-05-24T22:03:17.398-0500 I  NETWORK  [conn22] received client metadata from 192.168.101.72:65162 conn22: { driver: { name: "NetworkInterfaceTL", version: "4.2.25" }, os: { type: "Windows", name: "Microsoft Windows 10", architecture: "x86_64", version: "10.0 (build 19045)" } }
d20001| 2024-05-24T22:03:17.396-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20002
d20001| 2024-05-24T22:03:17.397-0500 I  REPL     [rsSync-0] Finished oplog application
d20001| 2024-05-24T22:03:17.481-0500 I  REPL     [rsBackgroundSync] Stopping replication producer
d20001| 2024-05-24T22:03:17.481-0500 I  REPL     [eventTerminate] Stopping replication storage threads
d20002| 2024-05-24T22:03:17.482-0500 I  NETWORK  [conn22] end connection 192.168.101.72:65162 (4 connections now open)
d20001| 2024-05-24T22:03:17.481-0500 I  ASIO     [RS] Killing all outstanding egress activity.
d20001| 2024-05-24T22:03:17.481-0500 I  ASIO     [RS] Killing all outstanding egress activity.
d20001| 2024-05-24T22:03:17.481-0500 I  CONNPOOL [RS] Dropping all pooled connections to LT-CMARINS:20000 due to ShutdownInProgress: Shutting down the connection pool
d20001| 2024-05-24T22:03:17.482-0500 I  REPL     [replexec-2] replSetStepUp request to LT-CMARINS:20002 failed due to CallbackCanceled: Callback canceled
d20001| 2024-05-24T22:03:17.482-0500 I  ASIO     [Replication] Killing all outstanding egress activity.
d20001| 2024-05-24T22:03:17.482-0500 I  CONNPOOL [Replication] Dropping all pooled connections to LT-CMARINS:20002 due to ShutdownInProgress: Shutting down the connection pool
d20001| 2024-05-24T22:03:17.482-0500 I  SHARDING [eventTerminate] Shutting down the ShardingInitializationMongoD
d20001| 2024-05-24T22:03:17.482-0500 I  REPL     [eventTerminate] Enqueuing the ReplicationStateTransitionLock for shutdown
d20001| 2024-05-24T22:03:17.482-0500 I  -        [eventTerminate] Killing all operations for shutdown
d20001| 2024-05-24T22:03:17.482-0500 I  COMMAND  [eventTerminate] Shutting down all open transactions
d20001| 2024-05-24T22:03:17.483-0500 I  REPL     [eventTerminate] Acquiring the ReplicationStateTransitionLock for shutdown
d20001| 2024-05-24T22:03:17.483-0500 I  INDEX    [eventTerminate] Shutting down the IndexBuildsCoordinator
d20001| 2024-05-24T22:03:17.483-0500 I  NETWORK  [eventTerminate] Shutting down the ReplicaSetMonitor
d20001| 2024-05-24T22:03:17.483-0500 I  REPL     [eventTerminate] Shutting down the LogicalTimeValidator
d20001| 2024-05-24T22:03:17.483-0500 I  CONTROL  [eventTerminate] Shutting down free monitoring
d20001| 2024-05-24T22:03:17.483-0500 I  CONTROL  [eventTerminate] Shutting down free monitoring
d20002| 2024-05-24T22:03:17.487-0500 I  REPL     [replication-3] Restarting oplog query due to error: InterruptedAtShutdown: error in fetcher batch callback :: caused by :: interrupted at shutdown. Last fetched optime: { ts: Timestamp(1716606195, 10), t: 2 }. Restarts remaining: 1
d20001| 2024-05-24T22:03:17.483-0500 I  FTDC     [eventTerminate] Shutting down full-time data capture
d20001| 2024-05-24T22:03:17.483-0500 I  FTDC     [eventTerminate] Shutting down full-time diagnostic data capture
d20001| 2024-05-24T22:03:17.486-0500 I  STORAGE  [eventTerminate] Shutting down the HealthLog
d20001| 2024-05-24T22:03:17.486-0500 I  STORAGE  [eventTerminate] Shutting down the storage engine
d20001| 2024-05-24T22:03:17.486-0500 I  STORAGE  [eventTerminate] Deregistering all the collections
d20001| 2024-05-24T22:03:17.486-0500 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
d20002| 2024-05-24T22:03:17.487-0500 I  REPL     [replication-3] Scheduled new oplog query Fetcher source: LT-CMARINS:20001 database: local query: { find: "oplog.rs", filter: { ts: { $gte: Timestamp(1716606195, 10) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 3, readConcern: { afterClusterTime: Timestamp(0, 1) } } query metadata: { $replData: 1, $oplogQueryData: 1, $readPreference: { mode: "secondaryPreferred" } } active: 1 findNetworkTimeout: 7000ms getMoreNetworkTimeout: 10000ms shutting down?: 0 first: 1 firstCommandScheduler: RemoteCommandRetryScheduler request: RemoteCommand 415 -- target:LT-CMARINS:20001 db:local cmd:{ find: "oplog.rs", filter: { ts: { $gte: Timestamp(1716606195, 10) } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 2000, batchSize: 13981010, term: 3, readConcern: { afterClusterTime: Timestamp(0, 1) } } active: 1 callbackHandle.valid: 1 callbackHandle.cancelled: 0 attempt: 1 retryPolicy: {type: "NoRetryPolicy"}
d20002| 2024-05-24T22:03:17.487-0500 I  REPL     [replication-2] Error returned from oplog query (no more query restarts left): InterruptedAtShutdown: error in fetcher batch callback :: caused by :: interrupted at shutdown
d20002| 2024-05-24T22:03:17.487-0500 W  REPL     [rsBackgroundSync] Fetcher stopped querying remote oplog with error: InterruptedAtShutdown: error in fetcher batch callback :: caused by :: interrupted at shutdown
d20002| 2024-05-24T22:03:17.488-0500 I  REPL     [rsBackgroundSync] Clearing sync source LT-CMARINS:20001 to choose a new one.
d20002| 2024-05-24T22:03:17.488-0500 I  REPL     [rsBackgroundSync] could not find member to sync from
d20001| 2024-05-24T22:03:17.486-0500 W  QUERY    [conn20] GetMore command executor error: FAILURE, status: InterruptedAtShutdown: interrupted at shutdown, stats: { stage: "COLLSCAN", nReturned: 2, executionTimeMillisEstimate: 0, works: 10, advanced: 2, needTime: 4, needYield: 0, saveState: 4, restoreState: 3, isEOF: 0, direction: "forward", docsExamined: 2 }
d20001| 2024-05-24T22:03:17.486-0500 I  STORAGE  [eventTerminate] Timestamp monitor shutting down
d20001| 2024-05-24T22:03:17.486-0500 I  STORAGE  [eventTerminate] WiredTigerKVEngine shutting down
d20001| 2024-05-24T22:03:17.486-0500 I  STORAGE  [eventTerminate] Shutting down session sweeper thread
d20001| 2024-05-24T22:03:17.487-0500 I  STORAGE  [eventTerminate] Finished shutting down session sweeper thread
d20001| 2024-05-24T22:03:17.487-0500 I  STORAGE  [eventTerminate] Shutting down journal flusher thread
d20002| 2024-05-24T22:03:17.492-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20000
d20002| 2024-05-24T22:03:17.493-0500 I  REPL_HB  [replexec-6] Heartbeat to LT-CMARINS:20001 failed after 2 retries, response status: InterruptedAtShutdown: interrupted at shutdown
d20002| 2024-05-24T22:03:17.493-0500 I  REPL     [replexec-6] Member LT-CMARINS:20001 is now in state RS_DOWN - interrupted at shutdown
d20001| 2024-05-24T22:03:17.572-0500 I  STORAGE  [eventTerminate] Finished shutting down journal flusher thread
d20001| 2024-05-24T22:03:17.572-0500 I  STORAGE  [eventTerminate] Shutting down checkpoint thread
d20001| 2024-05-24T22:03:17.572-0500 I  STORAGE  [eventTerminate] Finished shutting down checkpoint thread
d20001| 2024-05-24T22:03:17.593-0500 I  STORAGE  [eventTerminate] shutdown: removing fs lock...
d20001| 2024-05-24T22:03:17.594-0500 I  -        [eventTerminate] Dropping the scope cache for shutdown
d20001| 2024-05-24T22:03:17.594-0500 I  CONTROL  [eventTerminate] now exiting
d20001| 2024-05-24T22:03:17.594-0500 I  CONTROL  [eventTerminate] shutting down with code:0
2024-05-24T22:03:17.632-0500 I  -        [js] shell: stopped mongo program on port 20001
ReplSetTest stop *** Mongod in port 20001 shutdown with code (0) ***
ReplSetTest stop *** Shutting down mongod in port 20002 ***
d20002| 2024-05-24T22:03:17.638-0500 I  CONTROL  [eventTerminate] shutdown event signaled, will terminate after current cmd ends
d20002| 2024-05-24T22:03:17.638-0500 I  REPL     [eventTerminate] Stepping down the ReplicationCoordinator for shutdown, waitTime: 100ms
d20002| 2024-05-24T22:03:17.639-0500 I  SHARDING [eventTerminate] Shutting down the WaitForMajorityService
d20002| 2024-05-24T22:03:17.640-0500 I  CONTROL  [eventTerminate] Shutting down the LogicalSessionCache
d20002| 2024-05-24T22:03:17.640-0500 I  NETWORK  [eventTerminate] shutdown: going to close listening sockets...
d20002| 2024-05-24T22:03:17.640-0500 I  NETWORK  [eventTerminate] Shutting down the global connection pool
d20002| 2024-05-24T22:03:17.640-0500 I  STORAGE  [eventTerminate] Shutting down the FlowControlTicketholder
d20002| 2024-05-24T22:03:17.640-0500 I  -        [eventTerminate] Stopping further Flow Control ticket acquisitions.
d20002| 2024-05-24T22:03:17.640-0500 I  STORAGE  [eventTerminate] Shutting down the PeriodicThreadToAbortExpiredTransactions
d20002| 2024-05-24T22:03:17.640-0500 I  STORAGE  [eventTerminate] Shutting down the PeriodicThreadToDecreaseSnapshotHistoryIfNotNeeded
d20002| 2024-05-24T22:03:17.640-0500 I  REPL     [eventTerminate] Shutting down the ReplicationCoordinator
d20002| 2024-05-24T22:03:17.640-0500 I  REPL     [eventTerminate] shutting down replication subsystems
d20002| 2024-05-24T22:03:17.640-0500 I  REPL     [eventTerminate] Stopping replication reporter thread
d20002| 2024-05-24T22:03:17.640-0500 I  REPL     [SyncSourceFeedback] SyncSourceFeedback error sending update to LT-CMARINS:20001: CallbackCanceled: Reporter no longer valid
d20002| 2024-05-24T22:03:17.640-0500 I  REPL     [eventTerminate] Stopping replication fetcher thread
d20002| 2024-05-24T22:03:17.641-0500 I  REPL     [eventTerminate] Stopping replication applier thread
d20002| 2024-05-24T22:03:17.993-0500 W  NETWORK  [replexec-2] Failed to check socket connectivity: La operaci├│n se complet├│ correctamente.
d20002| 2024-05-24T22:03:17.993-0500 I  CONNPOOL [replexec-2] dropping unhealthy pooled connection to LT-CMARINS:20001
d20002| 2024-05-24T22:03:17.993-0500 I  CONNPOOL [Replication] Connecting to LT-CMARINS:20001
d20002| 2024-05-24T22:03:18.410-0500 I  REPL     [rsSync-0] Finished oplog application
d20002| 2024-05-24T22:03:18.492-0500 I  REPL     [rsBackgroundSync] Stopping replication producer
d20002| 2024-05-24T22:03:18.493-0500 I  REPL     [eventTerminate] Stopping replication storage threads
d20002| 2024-05-24T22:03:18.493-0500 I  ASIO     [RS] Killing all outstanding egress activity.
d20002| 2024-05-24T22:03:18.493-0500 I  ASIO     [RS] Killing all outstanding egress activity.
d20002| 2024-05-24T22:03:18.493-0500 I  CONNPOOL [RS] Dropping all pooled connections to LT-CMARINS:20000 due to ShutdownInProgress: Shutting down the connection pool
d20002| 2024-05-24T22:03:18.493-0500 I  CONNPOOL [RS] Dropping all pooled connections to LT-CMARINS:20001 due to ShutdownInProgress: Shutting down the connection pool
d20002| 2024-05-24T22:03:18.494-0500 I  ELECTION [replexec-2] VoteRequester(term 3) failed to receive response from LT-CMARINS:20000: CallbackCanceled: Callback canceled
d20002| 2024-05-24T22:03:18.495-0500 I  ELECTION [replexec-7] not becoming primary, we received insufficient votes
d20002| 2024-05-24T22:03:18.495-0500 I  ELECTION [replexec-7] Lost election
d20002| 2024-05-24T22:03:18.495-0500 I  COMMAND  [conn9] replSetStepUp request failed :: caused by :: CommandFailed: Election failed.
d20002| 2024-05-24T22:03:18.496-0500 I  COMMAND  [conn9] command admin.$cmd command: replSetStepUp { replSetStepUp: 1, skipDryRun: true, $clusterTime: { clusterTime: Timestamp(1716606195, 10), signature: { hash: BinData(0, 6FA138777909632A9439789FF3329B8437AB2B02), keyId: 7372766531333128197 } }, $db: "admin" } numYields:0 ok:0 errMsg:"Election failed." errName:CommandFailed errCode:125 reslen:230 locks:{} protocol:op_msg 2016ms
d20002| 2024-05-24T22:03:18.496-0500 I  ASIO     [Replication] Killing all outstanding egress activity.
d20002| 2024-05-24T22:03:18.496-0500 I  SHARDING [eventTerminate] Shutting down the ShardingInitializationMongoD
d20002| 2024-05-24T22:03:18.496-0500 I  NETWORK  [conn9] end connection 192.168.101.72:65104 (3 connections now open)
d20002| 2024-05-24T22:03:18.496-0500 I  REPL     [eventTerminate] Enqueuing the ReplicationStateTransitionLock for shutdown
d20002| 2024-05-24T22:03:18.496-0500 I  -        [eventTerminate] Killing all operations for shutdown
d20002| 2024-05-24T22:03:18.497-0500 I  COMMAND  [eventTerminate] Shutting down all open transactions
d20002| 2024-05-24T22:03:18.497-0500 I  REPL     [eventTerminate] Acquiring the ReplicationStateTransitionLock for shutdown
d20002| 2024-05-24T22:03:18.497-0500 I  INDEX    [eventTerminate] Shutting down the IndexBuildsCoordinator
d20002| 2024-05-24T22:03:18.497-0500 I  NETWORK  [eventTerminate] Shutting down the ReplicaSetMonitor
d20002| 2024-05-24T22:03:18.497-0500 I  REPL     [eventTerminate] Shutting down the LogicalTimeValidator
d20002| 2024-05-24T22:03:18.497-0500 I  CONTROL  [eventTerminate] Shutting down free monitoring
d20002| 2024-05-24T22:03:18.497-0500 I  CONTROL  [eventTerminate] Shutting down free monitoring
d20002| 2024-05-24T22:03:18.497-0500 I  FTDC     [eventTerminate] Shutting down full-time data capture
d20002| 2024-05-24T22:03:18.497-0500 I  FTDC     [eventTerminate] Shutting down full-time diagnostic data capture
d20002| 2024-05-24T22:03:18.501-0500 I  STORAGE  [eventTerminate] Shutting down the HealthLog
d20002| 2024-05-24T22:03:18.501-0500 I  STORAGE  [eventTerminate] Shutting down the storage engine
d20002| 2024-05-24T22:03:18.501-0500 I  STORAGE  [eventTerminate] Deregistering all the collections
d20002| 2024-05-24T22:03:18.501-0500 I  STORAGE  [WTOplogJournalThread] Oplog journal thread loop shutting down
d20002| 2024-05-24T22:03:18.502-0500 I  STORAGE  [eventTerminate] Timestamp monitor shutting down
d20002| 2024-05-24T22:03:18.502-0500 I  STORAGE  [eventTerminate] WiredTigerKVEngine shutting down
d20002| 2024-05-24T22:03:18.502-0500 I  STORAGE  [eventTerminate] Shutting down session sweeper thread
d20002| 2024-05-24T22:03:18.502-0500 I  STORAGE  [eventTerminate] Finished shutting down session sweeper thread
d20002| 2024-05-24T22:03:18.502-0500 I  STORAGE  [eventTerminate] Shutting down journal flusher thread
d20002| 2024-05-24T22:03:18.526-0500 I  STORAGE  [eventTerminate] Finished shutting down journal flusher thread
d20002| 2024-05-24T22:03:18.526-0500 I  STORAGE  [eventTerminate] Shutting down checkpoint thread
d20002| 2024-05-24T22:03:18.526-0500 I  STORAGE  [eventTerminate] Finished shutting down checkpoint thread
d20002| 2024-05-24T22:03:18.547-0500 I  STORAGE  [eventTerminate] shutdown: removing fs lock...
d20002| 2024-05-24T22:03:18.547-0500 I  -        [eventTerminate] Dropping the scope cache for shutdown
d20002| 2024-05-24T22:03:18.547-0500 I  CONTROL  [eventTerminate] now exiting
d20002| 2024-05-24T22:03:18.547-0500 I  CONTROL  [eventTerminate] shutting down with code:0
2024-05-24T22:03:18.583-0500 I  -        [js] shell: stopped mongo program on port 20002
ReplSetTest stop *** Mongod in port 20002 shutdown with code (0) ***
ReplSetTest stopSet stopped all replica set nodes.
ReplSetTest stopSet deleting all dbpaths
ReplSetTest stopSet deleting dbpath: /data/db/EquipoReplicaSet-0
ReplSetTest stopSet deleting dbpath: /data/db/EquipoReplicaSet-1
ReplSetTest stopSet deleting dbpath: /data/db/EquipoReplicaSet-2
ReplSetTest stopSet deleted all dbpaths
ReplSetTest stopSet *** Shut down repl set - test worked ****
> EquipoReplicaSet.stopSet()
